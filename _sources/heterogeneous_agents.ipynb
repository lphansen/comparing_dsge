{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Heterogeneous Agents \n",
    "Consider the environment in section 5. We need to solve the following:\n",
    "\\begin{align*}\n",
    "    \\begin{split}\n",
    "    {L}^e_{HJB} \\left(v^e, v^h, \\kappa, \\chi;x \\right) &= \\frac{\\rho_e}{1-\\rho_e} \\delta_e^{1 / \\rho_e} \\exp\\left[({1- \\frac{1}{\\rho_e}})v^e)\\right]-\\frac{\\delta_e}{1-\\rho_e}+r\\\\&+\\frac{1}{2 \\gamma_e} \\frac{\\left(\\Delta^e+\\pi^h \\cdot \\sigma_R\\right)^2}{\\left\\|\\sigma_R\\right\\|^2}\n",
    "+\\left[\\mu_X+\\frac{1-\\gamma_e}{\\gamma_e}\\left(\\frac{\\Delta^e+\\pi^h \\cdot \\sigma_R}{\\left\\|\\sigma_R\\right\\|^2}\\right) \\sigma_X \\sigma_R\\right] \\cdot \\partial_X v^e \\\\\n",
    "&+\\frac{1}{2}\\left[\\operatorname{tr}\\left(\\sigma_X^{\\prime} \\partial_{xx^{\\prime}} v^e \\sigma_X\\right)+\\frac{1-\\gamma_e}{\\gamma_e}\\left(\\sigma_X^{\\prime} \\partial_x v_e\\right)^{\\prime}\\left[\\gamma_e \\mathbb{I}_d+\\left(1-\\gamma_e\\right) \\frac{\\sigma_R \\sigma_R^{\\prime}}{\\left\\|\\sigma_R\\right\\|^2}\\right] \\sigma_X^{\\prime} \\partial_x v^e\\right]= 0 \n",
    "\\end{split}\\\\\n",
    "\\begin{split}\n",
    "    {L}^h_{HJB} \\left(v^e, v^h, \\kappa, \\chi;x \\right) &=\\frac{\\rho_h}{1-\\rho_h} \\delta_h^{1 / \\rho_h}  \\exp\\left[({1- \\frac{1}{\\rho_h}})v^h)\\right]-\\frac{\\delta_h}{1-\\rho_h}+r+\\frac{1}{2 \\gamma_h}\\|\\pi^h\\|^2\\\\&+\\left[\\mu_X+\\frac{1-\\gamma_h}{\\gamma_h} \\sigma_X \\pi^h\\right] \\cdot \\partial_x v^h +\\frac{1}{2}\\left[\\operatorname{tr}\\left(\\sigma_X^{\\prime} \\partial_{xx^{\\prime}} v^h \\sigma_X\\right)+\\frac{1-\\gamma_h}{\\gamma_h}\\left\\|\\sigma_X^{\\prime} \\partial_x v^h\\right\\|^2\\right]=0\\end{split} \\\\\n",
    "\\begin{split}\n",
    "    {L}_{\\kappa} \\left(v^e, v^h,\\kappa, \\chi;x \\right) &= \\min\\Big\\{ 1 - \\kappa, \\, w\\gamma_h (1-\\chi\\kappa) | \\sigma_R |^2 - (1-w) \\gamma_e \\chi \\kappa | \\sigma_R |^2  \\\\\n",
    "\t\\qquad &+ w(1-w) \\frac{\\alpha_e - \\alpha_h}{\\underline{\\chi} q} + w(1-w) \\left( \\sigma_x \\sigma_R \\right) \\cdot \\left[ (\\gamma_h-1)\\partial_x \\upsilon^h -  (\\gamma_e-1)\\partial_x \\upsilon^e \\right] \\Big\\} = 0\\\\\n",
    "\\end{split} \\\\\n",
    "\\begin{split}\n",
    "    {L}_{\\chi} \\left(v^e, v^h, \\kappa, \\chi;x \\right) &= \\min\\Big\\{ \\chi - \\underline{\\chi}, \\, \\Big[ ((1-w)\\gamma_e + w\\gamma_h) | D_{z} |^2 + (\\partial_w \\log q) D_{\\upsilon,z} - D_{\\upsilon,w} \\Big](\\chi - w) \\\\\n",
    " \\quad &+ w(1-w) (\\gamma_e - \\gamma_h) | D_{z} |^2 - D_{\\upsilon,z} \\Big\\} = 0\n",
    "\\end{split}\n",
    "\\end{align*}\n",
    "\n",
    "Where:\n",
    "\n",
    "\\begin{align*}\n",
    " D_{z} &\\doteq \\sqrt{z_2}\\sigma_k + \\sigma_{z}' \\partial_{z} \\log q \\\\\n",
    " D_{\\upsilon,w} &\\doteq w(1-w) | D_{z} |^2 \\partial_w  \\big[ (\\gamma_h - 1) \\upsilon^h - (\\gamma_e - 1)\\upsilon^e \\big] \\\\\n",
    " D_{\\upsilon,z} &\\doteq w(1-w) \\left(\\sigma_{z}D_{z} \\right) \\cdot \\partial_{z} \\big[ (\\gamma_h - 1) \\upsilon^h - (\\gamma_e - 1)\\upsilon^e  \\big]\n",
    "\\end{align*}\n",
    "\n",
    "Since $\\chi$ can be solved algebraically, we solve (1) to (3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Solution Overview\n",
    "### 4.1.1 Model Architecture\n",
    "We modify the `DeepGalerkinMethod` code from https://github.com/alialaradi/DeepGalerkinMethod. We construct an object `sim_NN` of class `DGMNet` with the following hyperparameters:\n",
    "\n",
    "```{list-table}\n",
    ":header-rows: 1\n",
    "\n",
    "* - Input\n",
    "  - Description\n",
    "  - Parameter used in paper\n",
    "* - `n_layers`\n",
    "  - Number of layers\n",
    "  - 2\n",
    "* - `units`\n",
    "  - Number of neurons in each layer\n",
    "  - 16\n",
    "* - `input_dim`\n",
    "  - Dimension of input into first layer\n",
    "  - 3 (This should be the same as the number of states)\n",
    "* - `activation`\n",
    "  - Activation function for all layers except the last\n",
    "  - tanh\n",
    "* - `final_activation`\n",
    "  - Activation function for final layer\n",
    "  - Identity function for first two dimensions; sigmoid for third dimension. This is so that...\n",
    "* - `seed`\n",
    "  - Seed for weight and bias initialization\n",
    "  - 256\n",
    "```\n",
    "\n",
    "We use a Glorot normal initializer to initialize weights and a Glorot uniform initializer to initialize the biases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 4.1.2 Training\n",
    "The training set is constructed by drawing uniformly from the three-dimensional cube bounded by [`wMin`,`zMin`,`vMin`] and [`wMax`,`zMax`,`vMax`]. The loss function is given by the mean squared error of $L$, where:\n",
    "\n",
    "$$\n",
    "L = {L}^e_{HJB} + {L}^h_{HJB} + p{L}_{\\kappa}\n",
    "$$\n",
    "\n",
    "Where $p$ is a penalization parameter. We compute gradients using `tf.GradientTape` and use an `L-BFGS-B` solver. The full list of parameters for the training stage are:\n",
    "\n",
    "```{list-table}\n",
    ":header-rows: 1\n",
    "\n",
    "* - Input\n",
    "  - Description\n",
    "  - Parameter used in paper\n",
    "* - `points_size`\n",
    "  - Determines the `batchSize`, which is $2^x$ where $x$ is `points_size`. Batch size is the number of training samples in each epoch\n",
    "  - 10\n",
    "* - `iter_num`\n",
    "  - Number of epochs, i.e. the number of complete passes through the training set\n",
    "  - 5\n",
    "* - `penalization`\n",
    "  - Penalty for violating $\\kappa$ constraint\n",
    "  - 10000\n",
    "* - `seed`\n",
    "  - Seed for drawing uniform samples\n",
    "  - 256 (same as seed for initialization)\n",
    "* - `max_iter`\n",
    "  - Maximum number of L-BFGS-B iterations (number of times parameters are updated) per epoch\n",
    "  - 100\n",
    "* - `maxfun`\n",
    "  - Maximum number of function evaluations per epoch\n",
    "  - 100\n",
    "* - `maxcor`\n",
    "  - The maximum number of variable metric corrections used to define the limited memory matrix used to compute the Hessian per epoch\n",
    "  - 100\n",
    "* - `maxls`\n",
    "  - Maximum number of line search steps per iteration used to find the optimal step-size\n",
    "  - 100\n",
    "* - `gtol`\n",
    "  - Iteration will stop when $\\max|proj(g_i)| \\leq$ `gtol` for each entry $i$ of the (projected) gradient vector\n",
    "  - Machine epsilon for float64 (~$2^{-16}$)\n",
    "* - `ftol`\n",
    "  - Iteration will stop when $\\frac{L^k - L^{k+1}}{\\max{|L^k|,|L^{k+1}|,1}} \\leq$ `ftol`\n",
    "  - Machine epsilon for float64 (~$2^{-16}$)\n",
    "* - `tolerance`\n",
    "  - Iteration will stop when, after fully completing an epoch, $L$ is less than `tolerance`\n",
    "  - $10^{-5}$\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 Model Parameters\n",
    "We also need to set model parameters. These will vary depending on the environment chosen from Section 5.1. By default, the following parameters are allowed as inputs to `main_BFGS`:\n",
    "```{list-table}\n",
    ":header-rows: 1\n",
    "\n",
    "* - Input\n",
    "  - Description\n",
    "  - Parameter used in paper\n",
    "* - `chiUnderline`\n",
    "  - Skin-in-the-game constraint\n",
    "  - $\\underline{\\chi}$\n",
    "* - `gamma_e`, `gamma_h`\n",
    "  - Expert and household uncertainty aversion\n",
    "  - $\\gamma_e, \\gamma_h$\n",
    "* - `a_e`, `a_h`\n",
    "  - Expert and household productivity\n",
    "  - $\\alpha_e, \\alpha_h$\n",
    "* - `delta_e`,`delta_h`\n",
    "  - Expert and household discount rate\n",
    "  - $\\delta_e, \\delta_h$\n",
    "* - `rho_e`,`rho_h`\n",
    "  - Expert and household inverse of IES\n",
    "  - $\\rho_e, \\rho_h$\n",
    "* - `lambda_d`\n",
    "  - Birth/death rate\n",
    "  - $\\lambda_d$\n",
    "* - `nu`\n",
    "  - Fraction of newborns which are experts\n",
    "  - $\\nu$\n",
    "* - `V_bar`\n",
    "  - Mean of $Z_2$\n",
    "  - $\\mu_2$\n",
    "* - `sigma_K_norm`, `sigma_Z_norm`, `sigma_V_norm`\n",
    "  - Normalization for variances; these are multiplied by the covariance matrix specified in `utils_para` to yield $\\sigma_k, \\sigma_1, \\sigma2$\n",
    "  - \n",
    "* - `wMin`, `wMax`\n",
    "  - Bounds for training set for $W$; the corresponding bounds for $Z_1$ and $Z_2$ can be edited in `utils_para`\n",
    "  - \n",
    "* - `nWealth`, `nZ`, `nV`\n",
    "  - Number of gridpoints for each state variable; this does not have any effect on the solution but will determine the evaluation of variables of interest using the solution at a later step\n",
    "  - \n",
    "* - `shock_expo`\n",
    "  - Determines whether the shock exposure matrix is \"upper_triangular\" or \"lower_triangular\"\n",
    "  - \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, the following parameters can be edited in the `utils_para` file. They do not vary across the models explored in the paper, but the user may wish to explore their own variations.\n",
    "\n",
    "```{list-table}\n",
    ":header-rows: 1\n",
    "\n",
    "* - Input\n",
    "  - Description\n",
    "  - Parameter used in paper\n",
    "  - Default used in paper\n",
    "* - `Z_bar`\n",
    "  - Mean of $Z^1$\n",
    "  - \n",
    "  - 0.0\n",
    "* - `lambda_Z`\n",
    "  - Persistence of $Z^1\n",
    "  - $\\beta_1$\n",
    "  - 0.056\n",
    "* - `lambda_V`\n",
    "  - Persistence of $Z^2$\n",
    "  - $\\beta_2$\n",
    "  - 0.194\n",
    "* - `alpha_K`\n",
    "  - Depreciation\n",
    "  - $\\eta_k$\n",
    "  - $\\alpha$\n",
    "  - 0.04\n",
    "* - `phi`\n",
    "  - Adjustment cost\n",
    "  - $\\phi$\n",
    "  - 8.0\n",
    "* - `covij`\n",
    "  - $i,j$ entry in shock exposure matrix \n",
    "  - \n",
    "  - See Table 1 in paper\n",
    "* - `numSds`\n",
    "  - Governs grid size for $Z^1$ and $Z^2$ (number of standard deviations from the mean)\n",
    "  - 5\n",
    "* - `zmin`,`zmax`\n",
    "  - Grid boundaries for $Z^1$\n",
    "  - $\\mu_1 \\pm SD Var{Z_1|Z_2=\\mu_2}$ where $S=$`numSds`\n",
    "* - `vmin`,`vmax`\n",
    "  - Grid boundaries for $Z^2$\n",
    "  - `vmin` = $10^{-8}$,`vmax` = $\\mu_2 + SD Var{Z_2|Z_2=\\mu_2}$ where $S=$`numSds`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Quick Start\n",
    "We can build and train the neural network as follows. First, we import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 13:19:02.969807: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-28 13:19:05.178721: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-28 13:19:06.389192: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/slurm-current-el8-x86_64/lib\n",
      "2024-08-28 13:19:06.389212: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-08-28 13:19:06.683674: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-28 13:19:17.699752: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/slurm-current-el8-x86_64/lib\n",
      "2024-08-28 13:19:17.699843: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/slurm-current-el8-x86_64/lib\n",
      "2024-08-28 13:19:17.699849: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-08-28 13:19:32.240512: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/slurm-current-el8-x86_64/lib\n",
      "2024-08-28 13:19:32.240561: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-08-28 13:19:32.240578: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (midway3-login3.rcc.local): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import time \n",
    "import os\n",
    "os.chdir(\"src/4\")\n",
    "from main_BFGS import main\n",
    "from utils_para import setModelParameters\n",
    "from utils_training import training_step_BFGS\n",
    "from utils_DGM import DGMNet\n",
    "os.chdir(\"../..\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.config.set_visible_devices([], 'GPU') # To enable GPU acceleration, comment out this line and ensure CUDA and cuDNN libraries are properly installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we set the model parameters and hyperparameters. In the following example, we have used a variant of Model RF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiUnderline = 1.0\n",
    "gamma_e = 4.0\n",
    "a_e=0.0922\n",
    "a_h=0.0\n",
    "gamma_h=4.0\n",
    "delta_e=0.0115\n",
    "delta_h=0.01\n",
    "lambda_d=0.0\n",
    "rho_e=1.0\n",
    "rho_h=1.0\n",
    "nu=0.1\n",
    "\n",
    "V_bar=0.0000063030303030303026\n",
    "sigma_K_norm=3.1707442821755683\n",
    "sigma_Z_norm=19.835431735873996\n",
    "sigma_V_norm=0.0010882177801089308\n",
    "wMin=0.01\n",
    "wMax=0.99\n",
    "\n",
    "nWealth=180\n",
    "nZ=30\n",
    "nV=30\n",
    "\n",
    "seed_=(256)\n",
    "n_layers_=(2)\n",
    "units_=(16)\n",
    "points_size_=(10)\n",
    "iter_num_=(5)\n",
    "penalization=10000\n",
    "\n",
    "BFGSmaxiter=100\n",
    "BFGSmaxfun=100\n",
    "action_name = 'test'\n",
    "\n",
    "seed=256\n",
    "n_layers=2\n",
    "units=16\n",
    "points_size=10\n",
    "iter_num=5\n",
    "penalization=10000\n",
    "BFGS_maxiter=100\n",
    "BFGS_maxfun=100\n",
    "shock_expo = 'upper_triangular'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 11:53:42.950166: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Batch 1\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7fe5e04964c0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "BFGS Iter: 1 loss: 2.4774472703476573\n",
      "BFGS Iter: 2 loss: 1.1956006049934733\n",
      "BFGS Iter: 3 loss: 1.1512525155491342\n",
      "BFGS Iter: 4 loss: 1.1129767803662238\n",
      "BFGS Iter: 5 loss: 0.66527442628344491\n",
      "BFGS Iter: 6 loss: 0.19045107418377538\n",
      "BFGS Iter: 7 loss: 0.14912483949077682\n",
      "BFGS Iter: 8 loss: 13735.611871315654\n",
      "BFGS Iter: 9 loss: 6.1972373051936556\n",
      "BFGS Iter: 10 loss: 0.1596903342691938\n",
      "BFGS Iter: 11 loss: 0.13320460614263718\n",
      "BFGS Iter: 12 loss: 0.10059469459515527\n",
      "BFGS Iter: 13 loss: 0.07474686259589601\n",
      "BFGS Iter: 14 loss: 0.062933798120950624\n",
      "BFGS Iter: 15 loss: 0.055086244251407859\n",
      "BFGS Iter: 16 loss: 0.050427814352636088\n",
      "BFGS Iter: 17 loss: 0.046813373478503034\n",
      "BFGS Iter: 18 loss: 0.045500246076412468\n",
      "BFGS Iter: 19 loss: 0.04387517781687314\n",
      "BFGS Iter: 20 loss: 0.091107656580451252\n",
      "BFGS Iter: 21 loss: 0.0342036619069961\n",
      "BFGS Iter: 22 loss: 0.031755537839112072\n",
      "BFGS Iter: 23 loss: 0.024450823213388515\n",
      "BFGS Iter: 24 loss: 0.072173266097987437\n",
      "BFGS Iter: 25 loss: 0.02098351616409698\n",
      "BFGS Iter: 26 loss: 0.28981045467710354\n",
      "BFGS Iter: 27 loss: 0.011887332558140942\n",
      "BFGS Iter: 28 loss: 0.037647404339732675\n",
      "BFGS Iter: 29 loss: 0.00902718593900408\n",
      "BFGS Iter: 30 loss: 0.0083789179332656033\n",
      "BFGS Iter: 31 loss: 0.0043935143303938324\n",
      "BFGS Iter: 32 loss: 0.0019368788908450379\n",
      "BFGS Iter: 33 loss: 0.0019099897959955852\n",
      "BFGS Iter: 34 loss: 0.0014738935433658501\n",
      "BFGS Iter: 35 loss: 0.0011593717042880736\n",
      "BFGS Iter: 36 loss: 0.000908164038048691\n",
      "BFGS Iter: 37 loss: 0.00075176866092291112\n",
      "BFGS Iter: 38 loss: 0.00054805996634202836\n",
      "BFGS Iter: 39 loss: 0.00051959944474631512\n",
      "BFGS Iter: 40 loss: 0.00045225661397642575\n",
      "BFGS Iter: 41 loss: 0.0004325621978176222\n",
      "BFGS Iter: 42 loss: 0.00035683277983640077\n",
      "BFGS Iter: 43 loss: 0.0003424233979344597\n",
      "BFGS Iter: 44 loss: 0.000329914761644039\n",
      "BFGS Iter: 45 loss: 0.00032742520569724423\n",
      "BFGS Iter: 46 loss: 0.00032544636316967935\n",
      "BFGS Iter: 47 loss: 0.00031352262369962976\n",
      "BFGS Iter: 48 loss: 0.00030225915501465875\n",
      "BFGS Iter: 49 loss: 0.00027523893339239481\n",
      "BFGS Iter: 50 loss: 0.00025455428426839213\n",
      "BFGS Iter: 51 loss: 0.00024578583089963576\n",
      "BFGS Iter: 52 loss: 0.00024285342973901885\n",
      "BFGS Iter: 53 loss: 0.00023994461890596813\n",
      "BFGS Iter: 54 loss: 0.00023861381196568589\n",
      "BFGS Iter: 55 loss: 0.00023673930657093907\n",
      "BFGS Iter: 56 loss: 0.00023398271997321796\n",
      "BFGS Iter: 57 loss: 0.00022724885180655128\n",
      "BFGS Iter: 58 loss: 0.00021661176044998102\n",
      "BFGS Iter: 59 loss: 0.00020958772227023991\n",
      "BFGS Iter: 60 loss: 0.0002064656223563504\n",
      "BFGS Iter: 61 loss: 0.00019922072684694085\n",
      "BFGS Iter: 62 loss: 0.00017271409691762808\n",
      "BFGS Iter: 63 loss: 0.00014857614158382586\n",
      "BFGS Iter: 64 loss: 0.00024695471443224689\n",
      "BFGS Iter: 65 loss: 0.00013835145106131489\n",
      "BFGS Iter: 66 loss: 0.00013451456369301468\n",
      "BFGS Iter: 67 loss: 0.00013161012137018582\n",
      "BFGS Iter: 68 loss: 0.00012613454285588814\n",
      "BFGS Iter: 69 loss: 0.00012144641553965568\n",
      "BFGS Iter: 70 loss: 0.00011831696831485425\n",
      "BFGS Iter: 71 loss: 0.00011658986349170722\n",
      "BFGS Iter: 72 loss: 0.00011495065149315101\n",
      "BFGS Iter: 73 loss: 0.00011182459290387857\n",
      "BFGS Iter: 74 loss: 0.00010701676672256478\n",
      "BFGS Iter: 75 loss: 0.00010168748247379941\n",
      "BFGS Iter: 76 loss: 9.8110563654184735e-05\n",
      "BFGS Iter: 77 loss: 9.7013183430058578e-05\n",
      "BFGS Iter: 78 loss: 9.6442862813273759e-05\n",
      "BFGS Iter: 79 loss: 9.5818499871771386e-05\n",
      "BFGS Iter: 80 loss: 9.3725689390033315e-05\n",
      "BFGS Iter: 81 loss: 9.0592041217983809e-05\n",
      "BFGS Iter: 82 loss: 8.4723022281452625e-05\n",
      "BFGS Iter: 83 loss: 7.8949903997356063e-05\n",
      "BFGS Iter: 84 loss: 7.70492580908571e-05\n",
      "BFGS Iter: 85 loss: 7.6541986492635109e-05\n",
      "BFGS Iter: 86 loss: 7.6155678845069355e-05\n",
      "BFGS Iter: 87 loss: 7.5955811036532e-05\n",
      "BFGS Iter: 88 loss: 7.5641444375039929e-05\n",
      "BFGS Iter: 89 loss: 7.4598212022948033e-05\n",
      "BFGS Iter: 90 loss: 6.929043309298374e-05\n",
      "BFGS Iter: 91 loss: 5.9968128687644348e-05\n",
      "BFGS Iter: 92 loss: 5.5785700736942215e-05\n",
      "BFGS Iter: 93 loss: 5.2484043662533347e-05\n",
      "BFGS Iter: 94 loss: 5.0133791024322124e-05\n",
      "BFGS Iter: 95 loss: 4.8850315791665443e-05\n",
      "BFGS Iter: 96 loss: 4.7110570759746623e-05\n",
      "BFGS Iter: 97 loss: 4.491745003882522e-05\n",
      "BFGS Iter: 98 loss: 4.0061435089068928e-05\n",
      "BFGS Iter: 99 loss: 3.613962132748868e-05\n",
      "BFGS Iter: 100 loss: 3.51466198559229e-05\n",
      "BFGS Iter: 101 loss: 3.4883861920420573e-05\n",
      "Elapsed time 38.9414 sec\n",
      "Training Batch 2\n",
      "BFGS Iter: 1 loss: 3.2853896971848968e-05\n",
      "BFGS Iter: 2 loss: 0.019707537745072244\n",
      "BFGS Iter: 3 loss: 0.00014041080336993437\n",
      "BFGS Iter: 4 loss: 3.1974377718675872e-05\n",
      "BFGS Iter: 5 loss: 3.1825184390630736e-05\n",
      "BFGS Iter: 6 loss: 3.1344167734114741e-05\n",
      "BFGS Iter: 7 loss: 3.1252179104972564e-05\n",
      "BFGS Iter: 8 loss: 3.0416883028541236e-05\n",
      "BFGS Iter: 9 loss: 2.97514132047265e-05\n",
      "BFGS Iter: 10 loss: 2.906501017422695e-05\n",
      "BFGS Iter: 11 loss: 2.8818583544234104e-05\n",
      "BFGS Iter: 12 loss: 2.873178819948239e-05\n",
      "BFGS Iter: 13 loss: 2.8648501538548452e-05\n",
      "BFGS Iter: 14 loss: 2.8449005933157758e-05\n",
      "BFGS Iter: 15 loss: 2.8064555371744166e-05\n",
      "BFGS Iter: 16 loss: 2.7536057681507427e-05\n",
      "BFGS Iter: 17 loss: 2.703641185822243e-05\n",
      "BFGS Iter: 18 loss: 2.6687933523042895e-05\n",
      "BFGS Iter: 19 loss: 2.6522887393995814e-05\n",
      "BFGS Iter: 20 loss: 2.6264218254959419e-05\n",
      "BFGS Iter: 21 loss: 2.591644718390245e-05\n",
      "BFGS Iter: 22 loss: 2.4977123780294386e-05\n",
      "BFGS Iter: 23 loss: 2.3383280580777118e-05\n",
      "BFGS Iter: 24 loss: 2.2759879544202166e-05\n",
      "BFGS Iter: 25 loss: 2.2252896993315572e-05\n",
      "BFGS Iter: 26 loss: 2.1371535914795528e-05\n",
      "BFGS Iter: 27 loss: 2.0839626254889541e-05\n",
      "BFGS Iter: 28 loss: 2.0777584427760023e-05\n",
      "BFGS Iter: 29 loss: 2.0736604962744527e-05\n",
      "BFGS Iter: 30 loss: 2.0705036193386124e-05\n",
      "BFGS Iter: 31 loss: 2.0655092647324191e-05\n",
      "BFGS Iter: 32 loss: 2.0598914750422025e-05\n",
      "BFGS Iter: 33 loss: 2.0468158345696189e-05\n",
      "BFGS Iter: 34 loss: 2.0224766860300472e-05\n",
      "BFGS Iter: 35 loss: 1.9839248942125531e-05\n",
      "BFGS Iter: 36 loss: 1.9341026918287342e-05\n",
      "BFGS Iter: 37 loss: 1.8884423073158643e-05\n",
      "BFGS Iter: 38 loss: 1.8702716459971356e-05\n",
      "BFGS Iter: 39 loss: 1.8560172826039611e-05\n",
      "BFGS Iter: 40 loss: 1.8276066722155523e-05\n",
      "BFGS Iter: 41 loss: 1.7623510034851014e-05\n",
      "BFGS Iter: 42 loss: 1.6761181733420085e-05\n",
      "BFGS Iter: 43 loss: 1.6166916889031392e-05\n",
      "BFGS Iter: 44 loss: 1.5472076204676365e-05\n",
      "BFGS Iter: 45 loss: 1.5024891047283445e-05\n",
      "BFGS Iter: 46 loss: 1.4355291727712163e-05\n",
      "BFGS Iter: 47 loss: 1.3642639885382408e-05\n",
      "BFGS Iter: 48 loss: 1.3508537886352953e-05\n",
      "BFGS Iter: 49 loss: 1.3444851352247259e-05\n",
      "BFGS Iter: 50 loss: 1.3359903255302055e-05\n",
      "BFGS Iter: 51 loss: 1.3272913830301804e-05\n",
      "BFGS Iter: 52 loss: 1.3207987129916955e-05\n",
      "BFGS Iter: 53 loss: 1.3101230685461094e-05\n",
      "BFGS Iter: 54 loss: 1.2988284528412209e-05\n",
      "BFGS Iter: 55 loss: 1.282990171102536e-05\n",
      "BFGS Iter: 56 loss: 1.2712032288942737e-05\n",
      "BFGS Iter: 57 loss: 1.2674735833415232e-05\n",
      "BFGS Iter: 58 loss: 1.2663329186623378e-05\n",
      "BFGS Iter: 59 loss: 1.2650315702993225e-05\n",
      "BFGS Iter: 60 loss: 1.2623578282506827e-05\n",
      "BFGS Iter: 61 loss: 1.2577814294733134e-05\n",
      "BFGS Iter: 62 loss: 1.2547208683358239e-05\n",
      "BFGS Iter: 63 loss: 1.2523502020011372e-05\n",
      "BFGS Iter: 64 loss: 1.2501757713314936e-05\n",
      "BFGS Iter: 65 loss: 1.2418363606262223e-05\n",
      "BFGS Iter: 66 loss: 1.2253280554965201e-05\n",
      "BFGS Iter: 67 loss: 1.2195432558519506e-05\n",
      "BFGS Iter: 68 loss: 1.2185728612095706e-05\n",
      "BFGS Iter: 69 loss: 1.2172212591885034e-05\n",
      "BFGS Iter: 70 loss: 1.2168082534604752e-05\n",
      "BFGS Iter: 71 loss: 1.216592102061464e-05\n",
      "BFGS Iter: 72 loss: 1.2160875524338406e-05\n",
      "BFGS Iter: 73 loss: 1.2133819802866951e-05\n",
      "BFGS Iter: 74 loss: 1.2109716961644602e-05\n",
      "BFGS Iter: 75 loss: 1.2087067091338671e-05\n",
      "BFGS Iter: 76 loss: 1.2076558024284849e-05\n",
      "BFGS Iter: 77 loss: 1.2066996255622948e-05\n",
      "BFGS Iter: 78 loss: 1.2053154613077278e-05\n",
      "BFGS Iter: 79 loss: 1.203797942341931e-05\n",
      "BFGS Iter: 80 loss: 1.2016844012736538e-05\n",
      "BFGS Iter: 81 loss: 1.200139477497608e-05\n",
      "BFGS Iter: 82 loss: 1.1988520697403073e-05\n",
      "BFGS Iter: 83 loss: 1.198157664545267e-05\n",
      "BFGS Iter: 84 loss: 1.1978585181529594e-05\n",
      "BFGS Iter: 85 loss: 1.1966552352106392e-05\n",
      "BFGS Iter: 86 loss: 1.1956102387720503e-05\n",
      "BFGS Iter: 87 loss: 1.1935969329296331e-05\n",
      "BFGS Iter: 88 loss: 1.1921091735959954e-05\n",
      "BFGS Iter: 89 loss: 1.1912455188382755e-05\n",
      "BFGS Iter: 90 loss: 1.191066868206912e-05\n",
      "BFGS Iter: 91 loss: 1.1910354321870175e-05\n",
      "BFGS Iter: 92 loss: 1.1909990710776239e-05\n",
      "BFGS Iter: 93 loss: 1.1909094263289071e-05\n",
      "BFGS Iter: 94 loss: 1.1906607107549928e-05\n",
      "BFGS Iter: 95 loss: 1.1900758789743032e-05\n",
      "BFGS Iter: 96 loss: 1.1886762849391672e-05\n",
      "BFGS Iter: 97 loss: 1.1866360902097644e-05\n",
      "BFGS Iter: 98 loss: 1.1851912471258075e-05\n",
      "BFGS Iter: 99 loss: 1.1829654621967488e-05\n",
      "BFGS Iter: 100 loss: 1.181186005704434e-05\n",
      "BFGS Iter: 101 loss: 1.1808721580096721e-05\n",
      "Elapsed time 13.4273 sec\n",
      "Training Batch 3\n",
      "BFGS Iter: 1 loss: 1.331064116882083e-05\n",
      "BFGS Iter: 2 loss: 0.06117408740760033\n",
      "BFGS Iter: 3 loss: 1.6545090774307306e-05\n",
      "BFGS Iter: 4 loss: 1.3233483451527528e-05\n",
      "BFGS Iter: 5 loss: 1.3229861876555701e-05\n",
      "BFGS Iter: 6 loss: 1.3220643103168207e-05\n",
      "BFGS Iter: 7 loss: 1.3218023683495404e-05\n",
      "BFGS Iter: 8 loss: 1.3192825006285791e-05\n",
      "BFGS Iter: 9 loss: 1.3162709506410751e-05\n",
      "BFGS Iter: 10 loss: 1.3122478405834297e-05\n",
      "BFGS Iter: 11 loss: 1.3086652696287559e-05\n",
      "BFGS Iter: 12 loss: 1.3066946734789399e-05\n",
      "BFGS Iter: 13 loss: 1.30625645234478e-05\n",
      "BFGS Iter: 14 loss: 1.3056600028652622e-05\n",
      "BFGS Iter: 15 loss: 1.3041742751643852e-05\n",
      "BFGS Iter: 16 loss: 1.302278511422033e-05\n",
      "BFGS Iter: 17 loss: 1.3015263917683468e-05\n",
      "BFGS Iter: 18 loss: 1.3010882437890982e-05\n",
      "BFGS Iter: 19 loss: 1.3007174746827917e-05\n",
      "BFGS Iter: 20 loss: 1.3003567895294272e-05\n",
      "BFGS Iter: 21 loss: 1.2994063999200187e-05\n",
      "BFGS Iter: 22 loss: 1.2976924536905825e-05\n",
      "BFGS Iter: 23 loss: 1.2957821812855494e-05\n",
      "BFGS Iter: 24 loss: 1.2945510229395388e-05\n",
      "BFGS Iter: 25 loss: 1.2933797095940215e-05\n",
      "BFGS Iter: 26 loss: 1.2924884708960356e-05\n",
      "BFGS Iter: 27 loss: 1.2914824453347176e-05\n",
      "BFGS Iter: 28 loss: 1.2907758553489387e-05\n",
      "BFGS Iter: 29 loss: 1.2902529350726502e-05\n",
      "BFGS Iter: 30 loss: 1.2892655423718043e-05\n",
      "BFGS Iter: 31 loss: 1.2878869677871708e-05\n",
      "BFGS Iter: 32 loss: 1.2855464224573348e-05\n",
      "BFGS Iter: 33 loss: 1.2836326345029857e-05\n",
      "BFGS Iter: 34 loss: 1.282503585884498e-05\n",
      "BFGS Iter: 35 loss: 1.2819832876536658e-05\n",
      "BFGS Iter: 36 loss: 1.2817327177132516e-05\n",
      "BFGS Iter: 37 loss: 1.2814583416266755e-05\n",
      "BFGS Iter: 38 loss: 1.2812970776046914e-05\n",
      "BFGS Iter: 39 loss: 1.2811340914372243e-05\n",
      "BFGS Iter: 40 loss: 1.2808473901933942e-05\n",
      "BFGS Iter: 41 loss: 1.2804617061602693e-05\n",
      "BFGS Iter: 42 loss: 1.2799461734615346e-05\n",
      "BFGS Iter: 43 loss: 1.2791872909612326e-05\n",
      "BFGS Iter: 44 loss: 1.2775845340300466e-05\n",
      "BFGS Iter: 45 loss: 1.2767558545070499e-05\n",
      "BFGS Iter: 46 loss: 1.2765786028034198e-05\n",
      "BFGS Iter: 47 loss: 1.2765456915944788e-05\n",
      "BFGS Iter: 48 loss: 1.2764954898250717e-05\n",
      "BFGS Iter: 49 loss: 1.2763820297186977e-05\n",
      "BFGS Iter: 50 loss: 1.2761370314026455e-05\n",
      "BFGS Iter: 51 loss: 1.275633242947466e-05\n",
      "BFGS Iter: 52 loss: 1.2748364647824511e-05\n",
      "BFGS Iter: 53 loss: 1.2737479564954124e-05\n",
      "BFGS Iter: 54 loss: 1.2731536537342279e-05\n",
      "BFGS Iter: 55 loss: 1.2726402028368688e-05\n",
      "BFGS Iter: 56 loss: 1.2724893055359673e-05\n",
      "BFGS Iter: 57 loss: 1.2722910755738014e-05\n",
      "BFGS Iter: 58 loss: 1.2719392273903786e-05\n",
      "BFGS Iter: 59 loss: 1.2711735264065272e-05\n",
      "BFGS Iter: 60 loss: 1.2704860674004855e-05\n",
      "BFGS Iter: 61 loss: 1.27021993723173e-05\n",
      "BFGS Iter: 62 loss: 1.2701273997595555e-05\n",
      "BFGS Iter: 63 loss: 1.2701021816793273e-05\n",
      "BFGS Iter: 64 loss: 1.2700517502319772e-05\n",
      "BFGS Iter: 65 loss: 1.269903508238038e-05\n",
      "BFGS Iter: 66 loss: 1.2697087291156104e-05\n",
      "BFGS Iter: 67 loss: 1.2693290446662503e-05\n",
      "BFGS Iter: 68 loss: 1.2687183746506989e-05\n",
      "BFGS Iter: 69 loss: 1.2682668907493189e-05\n",
      "BFGS Iter: 70 loss: 1.2679415896418426e-05\n",
      "BFGS Iter: 71 loss: 1.2676845117611318e-05\n",
      "BFGS Iter: 72 loss: 1.2673213507258254e-05\n",
      "BFGS Iter: 73 loss: 1.2666559781308332e-05\n",
      "BFGS Iter: 74 loss: 1.2656686082966439e-05\n",
      "BFGS Iter: 75 loss: 1.2644999148520057e-05\n",
      "BFGS Iter: 76 loss: 1.2635209939852263e-05\n",
      "BFGS Iter: 77 loss: 1.2630498568379768e-05\n",
      "BFGS Iter: 78 loss: 1.262936268884058e-05\n",
      "BFGS Iter: 79 loss: 1.2628221954083415e-05\n",
      "BFGS Iter: 80 loss: 1.2628029582622525e-05\n",
      "BFGS Iter: 81 loss: 1.262792602962517e-05\n",
      "BFGS Iter: 82 loss: 1.262772463638237e-05\n",
      "BFGS Iter: 83 loss: 1.262706943312788e-05\n",
      "BFGS Iter: 84 loss: 1.2624294992242655e-05\n",
      "BFGS Iter: 85 loss: 1.2618450273525895e-05\n",
      "BFGS Iter: 86 loss: 1.2609322074630907e-05\n",
      "BFGS Iter: 87 loss: 1.2598401519292362e-05\n",
      "BFGS Iter: 88 loss: 1.2590384564064844e-05\n",
      "BFGS Iter: 89 loss: 1.2587779992697465e-05\n",
      "BFGS Iter: 90 loss: 1.258765922461213e-05\n",
      "BFGS Iter: 91 loss: 1.2587290535380229e-05\n",
      "BFGS Iter: 92 loss: 1.2587197180692745e-05\n",
      "BFGS Iter: 93 loss: 1.2586706782716528e-05\n",
      "BFGS Iter: 94 loss: 1.2585824920184296e-05\n",
      "BFGS Iter: 95 loss: 1.2583355677049011e-05\n",
      "BFGS Iter: 96 loss: 1.257742418799933e-05\n",
      "BFGS Iter: 97 loss: 1.2565273036975706e-05\n",
      "BFGS Iter: 98 loss: 1.2548872096132877e-05\n",
      "BFGS Iter: 99 loss: 1.2535809180398835e-05\n",
      "BFGS Iter: 100 loss: 1.2530088247677251e-05\n",
      "BFGS Iter: 101 loss: 1.2528984134717129e-05\n",
      "Elapsed time 13.7815 sec\n",
      "Training Batch 4\n",
      "BFGS Iter: 1 loss: 1.2934253125994222e-05\n",
      "BFGS Iter: 2 loss: 0.022237867180928024\n",
      "BFGS Iter: 3 loss: 3.5087285345516575e-05\n",
      "BFGS Iter: 4 loss: 1.2748799764896702e-05\n",
      "BFGS Iter: 5 loss: 1.2684513583115664e-05\n",
      "BFGS Iter: 6 loss: 1.249150200462084e-05\n",
      "BFGS Iter: 7 loss: 1.2368280693659667e-05\n",
      "BFGS Iter: 8 loss: 1.2363141064484407e-05\n",
      "BFGS Iter: 9 loss: 1.2344596450679788e-05\n",
      "BFGS Iter: 10 loss: 1.2244304824844164e-05\n",
      "BFGS Iter: 11 loss: 1.2215863286743963e-05\n",
      "BFGS Iter: 12 loss: 1.2205716259213079e-05\n",
      "BFGS Iter: 13 loss: 1.2202306969429472e-05\n",
      "BFGS Iter: 14 loss: 1.219602381087838e-05\n",
      "BFGS Iter: 15 loss: 1.2183416717284681e-05\n",
      "BFGS Iter: 16 loss: 1.216555188607241e-05\n",
      "BFGS Iter: 17 loss: 1.213824387136914e-05\n",
      "BFGS Iter: 18 loss: 1.2121873224964583e-05\n",
      "BFGS Iter: 19 loss: 1.2114396371794193e-05\n",
      "BFGS Iter: 20 loss: 1.2091100146216405e-05\n",
      "BFGS Iter: 21 loss: 1.20618082017786e-05\n",
      "BFGS Iter: 22 loss: 1.2024929276501241e-05\n",
      "BFGS Iter: 23 loss: 1.2004709867961343e-05\n",
      "BFGS Iter: 24 loss: 1.2000014343663818e-05\n",
      "BFGS Iter: 25 loss: 1.1996822486851663e-05\n",
      "BFGS Iter: 26 loss: 1.1989850270745779e-05\n",
      "BFGS Iter: 27 loss: 1.1974217370844448e-05\n",
      "BFGS Iter: 28 loss: 1.1946488450148227e-05\n",
      "BFGS Iter: 29 loss: 1.1913115843031066e-05\n",
      "BFGS Iter: 30 loss: 1.1894778447483723e-05\n",
      "BFGS Iter: 31 loss: 1.18910343952307e-05\n",
      "BFGS Iter: 32 loss: 1.1890089907808542e-05\n",
      "BFGS Iter: 33 loss: 1.1888383677046635e-05\n",
      "BFGS Iter: 34 loss: 1.1883279903485097e-05\n",
      "BFGS Iter: 35 loss: 1.18726499949084e-05\n",
      "BFGS Iter: 36 loss: 1.1855289160002535e-05\n",
      "BFGS Iter: 37 loss: 1.182632836397997e-05\n",
      "BFGS Iter: 38 loss: 1.1813207373814069e-05\n",
      "BFGS Iter: 39 loss: 1.1810327741296157e-05\n",
      "BFGS Iter: 40 loss: 1.1804946454478749e-05\n",
      "BFGS Iter: 41 loss: 1.1799320112426194e-05\n",
      "BFGS Iter: 42 loss: 1.1784198426799898e-05\n",
      "BFGS Iter: 43 loss: 1.1769579908185478e-05\n",
      "BFGS Iter: 44 loss: 1.1767728109488193e-05\n",
      "BFGS Iter: 45 loss: 1.1766500347053901e-05\n",
      "BFGS Iter: 46 loss: 1.1761919906735553e-05\n",
      "BFGS Iter: 47 loss: 1.1739475105618486e-05\n",
      "BFGS Iter: 48 loss: 1.1708020101422758e-05\n",
      "BFGS Iter: 49 loss: 1.1670674598939108e-05\n",
      "BFGS Iter: 50 loss: 1.1623827232351979e-05\n",
      "BFGS Iter: 51 loss: 1.1605535208677066e-05\n",
      "BFGS Iter: 52 loss: 1.1601464777961568e-05\n",
      "BFGS Iter: 53 loss: 1.1597955390530642e-05\n",
      "BFGS Iter: 54 loss: 1.1586662443935898e-05\n",
      "BFGS Iter: 55 loss: 1.1580133780187473e-05\n",
      "BFGS Iter: 56 loss: 1.156435494533015e-05\n",
      "BFGS Iter: 57 loss: 1.1539723572476787e-05\n",
      "BFGS Iter: 58 loss: 1.1532189883250412e-05\n",
      "BFGS Iter: 59 loss: 1.1529285133376485e-05\n",
      "BFGS Iter: 60 loss: 1.1528397670048011e-05\n",
      "BFGS Iter: 61 loss: 1.1521689318842587e-05\n",
      "BFGS Iter: 62 loss: 1.1508087374335811e-05\n",
      "BFGS Iter: 63 loss: 1.1476676378203691e-05\n",
      "BFGS Iter: 64 loss: 1.1445097641256559e-05\n",
      "BFGS Iter: 65 loss: 1.1416397252667121e-05\n",
      "BFGS Iter: 66 loss: 1.1400985805566946e-05\n",
      "BFGS Iter: 67 loss: 1.139254947373997e-05\n",
      "BFGS Iter: 68 loss: 1.1380127286031163e-05\n",
      "BFGS Iter: 69 loss: 1.1367041867669604e-05\n",
      "BFGS Iter: 70 loss: 1.1354795170612564e-05\n",
      "BFGS Iter: 71 loss: 1.1350218161038208e-05\n",
      "BFGS Iter: 72 loss: 1.1347431232098256e-05\n",
      "BFGS Iter: 73 loss: 1.1342765436043796e-05\n",
      "BFGS Iter: 74 loss: 1.1337951586426075e-05\n",
      "BFGS Iter: 75 loss: 1.1326444235439111e-05\n",
      "BFGS Iter: 76 loss: 1.1315133169016556e-05\n",
      "BFGS Iter: 77 loss: 1.1305252551126212e-05\n",
      "BFGS Iter: 78 loss: 1.1301318383477032e-05\n",
      "BFGS Iter: 79 loss: 1.1299828189733894e-05\n",
      "BFGS Iter: 80 loss: 1.1297910483081172e-05\n",
      "BFGS Iter: 81 loss: 1.1294123159386268e-05\n",
      "BFGS Iter: 82 loss: 1.1284997025994963e-05\n",
      "BFGS Iter: 83 loss: 1.1272374146795017e-05\n",
      "BFGS Iter: 84 loss: 1.1262237728419937e-05\n",
      "BFGS Iter: 85 loss: 1.1254497290392012e-05\n",
      "BFGS Iter: 86 loss: 1.1247674993836394e-05\n",
      "BFGS Iter: 87 loss: 1.1241008582186026e-05\n",
      "BFGS Iter: 88 loss: 1.1229533749776404e-05\n",
      "BFGS Iter: 89 loss: 1.1223094868210285e-05\n",
      "BFGS Iter: 90 loss: 1.1221029790459714e-05\n",
      "BFGS Iter: 91 loss: 1.1220563854183987e-05\n",
      "BFGS Iter: 92 loss: 1.1220395662515568e-05\n",
      "BFGS Iter: 93 loss: 1.121967406397467e-05\n",
      "BFGS Iter: 94 loss: 1.1215132161734005e-05\n",
      "BFGS Iter: 95 loss: 1.1209151111831868e-05\n",
      "BFGS Iter: 96 loss: 1.1197307803262909e-05\n",
      "BFGS Iter: 97 loss: 1.1186821861820828e-05\n",
      "BFGS Iter: 98 loss: 1.1181929521796944e-05\n",
      "BFGS Iter: 99 loss: 1.1181207434858048e-05\n",
      "BFGS Iter: 100 loss: 1.118102366166359e-05\n",
      "BFGS Iter: 101 loss: 1.1180886294138432e-05\n",
      "Elapsed time 13.1249 sec\n",
      "Training Batch 5\n",
      "BFGS Iter: 1 loss: 3.5371236143115144e-05\n",
      "BFGS Iter: 2 loss: 0.14220276672329604\n",
      "BFGS Iter: 3 loss: 0.0053646011810574365\n",
      "BFGS Iter: 4 loss: 0.00031364060581301234\n",
      "BFGS Iter: 5 loss: 1.8928635540105462e-05\n",
      "BFGS Iter: 6 loss: 1.7790417724596251e-05\n",
      "BFGS Iter: 7 loss: 1.5658651419098762e-05\n",
      "BFGS Iter: 8 loss: 1.5400933235362e-05\n",
      "BFGS Iter: 9 loss: 1.5387480853495626e-05\n",
      "BFGS Iter: 10 loss: 1.5331273113404196e-05\n",
      "BFGS Iter: 11 loss: 1.5229814501211383e-05\n",
      "BFGS Iter: 12 loss: 1.4960227036595818e-05\n",
      "BFGS Iter: 13 loss: 1.4468751921052961e-05\n",
      "BFGS Iter: 14 loss: 1.3845158095502893e-05\n",
      "BFGS Iter: 15 loss: 1.3403873135908949e-05\n",
      "BFGS Iter: 16 loss: 1.3246065627405587e-05\n",
      "BFGS Iter: 17 loss: 1.3221379859331613e-05\n",
      "BFGS Iter: 18 loss: 1.3199607297060127e-05\n",
      "BFGS Iter: 19 loss: 1.3144872604214214e-05\n",
      "BFGS Iter: 20 loss: 1.3053734001415056e-05\n",
      "BFGS Iter: 21 loss: 1.2796692896697949e-05\n",
      "BFGS Iter: 22 loss: 1.2329643930171517e-05\n",
      "BFGS Iter: 23 loss: 1.2196946630989999e-05\n",
      "BFGS Iter: 24 loss: 1.2112374293463313e-05\n",
      "BFGS Iter: 25 loss: 1.1995618308926672e-05\n",
      "BFGS Iter: 26 loss: 1.192519068129695e-05\n",
      "BFGS Iter: 27 loss: 1.1907527560263758e-05\n",
      "BFGS Iter: 28 loss: 1.1872807374446712e-05\n",
      "BFGS Iter: 29 loss: 1.186656525950388e-05\n",
      "BFGS Iter: 30 loss: 1.1865108259411649e-05\n",
      "BFGS Iter: 31 loss: 1.1863998629821241e-05\n",
      "BFGS Iter: 32 loss: 1.1860723285461483e-05\n",
      "BFGS Iter: 33 loss: 1.1853197029721009e-05\n",
      "BFGS Iter: 34 loss: 1.1835622095321231e-05\n",
      "BFGS Iter: 35 loss: 1.1803717724713043e-05\n",
      "BFGS Iter: 36 loss: 1.1764876259997913e-05\n",
      "BFGS Iter: 37 loss: 1.1739488157964466e-05\n",
      "BFGS Iter: 38 loss: 1.173195844411259e-05\n",
      "BFGS Iter: 39 loss: 1.1730718823954479e-05\n",
      "BFGS Iter: 40 loss: 1.1729250216689364e-05\n",
      "BFGS Iter: 41 loss: 1.172461525986897e-05\n",
      "BFGS Iter: 42 loss: 1.1713365115901901e-05\n",
      "BFGS Iter: 43 loss: 1.168818750167371e-05\n",
      "BFGS Iter: 44 loss: 1.1644935853311753e-05\n",
      "BFGS Iter: 45 loss: 1.159274261341498e-05\n",
      "BFGS Iter: 46 loss: 1.1563088949500705e-05\n",
      "BFGS Iter: 47 loss: 1.1556632573438674e-05\n",
      "BFGS Iter: 48 loss: 1.1554112040634257e-05\n",
      "BFGS Iter: 49 loss: 1.1549878581285814e-05\n",
      "BFGS Iter: 50 loss: 1.1539610643148062e-05\n",
      "BFGS Iter: 51 loss: 1.1522281942447986e-05\n",
      "BFGS Iter: 52 loss: 1.149251415014182e-05\n",
      "BFGS Iter: 53 loss: 1.1479392333423878e-05\n",
      "BFGS Iter: 54 loss: 1.1475994363881961e-05\n",
      "BFGS Iter: 55 loss: 1.1468372225899354e-05\n",
      "BFGS Iter: 56 loss: 1.1456541320631684e-05\n",
      "BFGS Iter: 57 loss: 1.1439399776759038e-05\n",
      "BFGS Iter: 58 loss: 1.1410725492089062e-05\n",
      "BFGS Iter: 59 loss: 1.1356054766756423e-05\n",
      "BFGS Iter: 60 loss: 1.1330061545090437e-05\n",
      "BFGS Iter: 61 loss: 1.1306432112056774e-05\n",
      "BFGS Iter: 62 loss: 1.1288200587281669e-05\n",
      "BFGS Iter: 63 loss: 1.1272524142312414e-05\n",
      "BFGS Iter: 64 loss: 1.1266858116681203e-05\n",
      "BFGS Iter: 65 loss: 1.1253927459287215e-05\n",
      "BFGS Iter: 66 loss: 1.1236607367987663e-05\n",
      "BFGS Iter: 67 loss: 1.121619986484418e-05\n",
      "BFGS Iter: 68 loss: 1.120775718419495e-05\n",
      "BFGS Iter: 69 loss: 1.1206452393275113e-05\n",
      "BFGS Iter: 70 loss: 1.1206267834597727e-05\n",
      "BFGS Iter: 71 loss: 1.1205816838928572e-05\n",
      "BFGS Iter: 72 loss: 1.1202193385177711e-05\n",
      "BFGS Iter: 73 loss: 1.1194368907026998e-05\n",
      "BFGS Iter: 74 loss: 1.1183837415402236e-05\n",
      "BFGS Iter: 75 loss: 1.1174997964410506e-05\n",
      "BFGS Iter: 76 loss: 1.1171030563697652e-05\n",
      "BFGS Iter: 77 loss: 1.1170242325112961e-05\n",
      "BFGS Iter: 78 loss: 1.116710340229912e-05\n",
      "BFGS Iter: 79 loss: 1.1142125068001499e-05\n",
      "BFGS Iter: 80 loss: 1.1135492609919581e-05\n",
      "BFGS Iter: 81 loss: 1.1133476119579804e-05\n",
      "BFGS Iter: 82 loss: 1.1133258709515484e-05\n",
      "BFGS Iter: 83 loss: 1.1133026775013508e-05\n",
      "BFGS Iter: 84 loss: 1.1132451389931068e-05\n",
      "BFGS Iter: 85 loss: 1.1130934728269286e-05\n",
      "BFGS Iter: 86 loss: 1.112715593477359e-05\n",
      "BFGS Iter: 87 loss: 1.1118315783131395e-05\n",
      "BFGS Iter: 88 loss: 1.1101161602659784e-05\n",
      "BFGS Iter: 89 loss: 1.107922939843552e-05\n",
      "BFGS Iter: 90 loss: 1.1063589810676235e-05\n",
      "BFGS Iter: 91 loss: 1.105754572859437e-05\n",
      "BFGS Iter: 92 loss: 1.1056549014404436e-05\n",
      "BFGS Iter: 93 loss: 1.1055826285149645e-05\n",
      "BFGS Iter: 94 loss: 1.1053544796972902e-05\n",
      "BFGS Iter: 95 loss: 1.1048119382793432e-05\n",
      "BFGS Iter: 96 loss: 1.1036070754941427e-05\n",
      "BFGS Iter: 97 loss: 1.1016533819418808e-05\n",
      "BFGS Iter: 98 loss: 1.0985942212474907e-05\n",
      "BFGS Iter: 99 loss: 1.0969796385295971e-05\n",
      "BFGS Iter: 100 loss: 1.0964485214369811e-05\n",
      "BFGS Iter: 101 loss: 1.0959386904055931e-05\n",
      "Elapsed time 14.2118 sec\n",
      "Tolerance reached. Current loss: 1.095938690405593e-05 Batches: 5\n",
      "Elapsed time for training 94.0623 sec\n"
     ]
    }
   ],
   "source": [
    "main(action_name, nWealth, nZ, nV, V_bar, sigma_K_norm, sigma_Z_norm, sigma_V_norm, wMin, wMax, chiUnderline, a_e, a_h, gamma_e, gamma_h, rho_e, rho_h, delta_e, delta_h, lambda_d, nu, shock_expo, n_layers, points_size, iter_num, units, seed, penalization, BFGS_maxiter, BFGS_maxfun)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a solution, we can compute variables of interest, which can subsequently be used to compute shock elasticities. By default, `main_variable` computes the following variables. Unless specified otherwise, the variables are evaluated on an array with dimension [`nWealth`,`nZ`,`nV`].\n",
    "```{list-table}\n",
    ":header-rows: 1\n",
    "\n",
    "* - Output\n",
    "  - Description\n",
    "  - Notation used in paper\n",
    "* - `W_NN`, `Z_NN`, `V_NN`\n",
    "  - The values of $W$, $Z_1$ and $Z_2$ on the state-space grid\n",
    "  - \n",
    "* - `XiE_NN`, `XiH_NN`\n",
    "  - Expert and household value functions\n",
    "  - $V_e$, $V_h$\n",
    "* - `logXiE_NN`, `logXiH_NN`\n",
    "  - Log expert and household value functions\n",
    "  - $\\hat{V}_e$, $\\hat{V}_h$\n",
    "* - `chi_NN`\n",
    "  - Expert equity retention\n",
    "  - $\\chi$\n",
    "* - `kappa_NN`\n",
    "  - Expert capital share\n",
    "  - $\\kappa$\n",
    "* - `r_NN`\n",
    "  - Risk-free rate\n",
    "  - $r$\n",
    "* - `q_NN`\n",
    "  - Price of capital\n",
    "  - $Q$\n",
    "* - `sigmaW_NN`,`sigmaZ_NN`,`sigmaV_NN`\n",
    "  - State volatilities \n",
    "  - $Z^2 \\sigma_w$,$Z^2 \\sigma_1$, $Z^2 \\sigma_2$\n",
    "* - `muW_NN`,`muZ_NN`,`muV_NN`\n",
    "  - State drifts\n",
    "  - $\\mu_w$,$\\mu_1$,$\\mu_2$\n",
    "* - `muK_NN`\n",
    "  - Log capital drift\n",
    "  - $\\mu_{k}$\n",
    "* - `sigmaK_NN`\n",
    "  - Log capital diffusin\n",
    "  - $\\sigma_{k}$\n",
    "* - `muQ_NN`\n",
    "  - Capital price drift\n",
    "  - $\\mu_q$\n",
    "* - `sigmaQ_NN`\n",
    "  - Capital price diffusion\n",
    "  - $\\sigma_q$\n",
    "* - `sigmaR_NN`\n",
    "  - Capital return volatility\n",
    "  - $\\sigma_r$\n",
    "* - `deltaE_NN`, `deltaH_NN`\n",
    "  - Expert and household risk premium wedge\n",
    "  - $\\Delta^e$,$\\Delta^h$\n",
    "* - `PiE_NN`, `PiH_NN`\n",
    "  - Expert and household equity risk price\n",
    "  - $\\pi_e$,$\\pi_h$\n",
    "* - `betaE_NN`,`betaH_NN`\n",
    "  - \n",
    "  - $\\frac{\\chi \\kappa}{W}$, $\\frac{1- \\kappa}{W}$\n",
    "* - `HJB_E_NN`, `HJB_H_NN`, `kappa_min_NN`\n",
    "  - RHS of HJB equations and $\\kappa$ constraint evaluated on the state space grid\n",
    "  - $L^e$, $L^h$, $L^{\\kappa}$\n",
    "* - `HJBE_validation_MSE`, `HJBH_validation_MSE`, `kappa_validation_MSE`\n",
    "  - Loss function (scalar)\n",
    "  - \n",
    "* - `dent_NN`\n",
    "  - Stationary density\n",
    "  - \n",
    "* - `dX_logXiE_NN`, `dX_logXiH_NN`, `dX2_logXiE_NN`, `dX2_logXiH_NN`\n",
    "  - First and second derivatives of expert and household value function with respect to each of the states; separate objects for each state are also included\n",
    "  - \n",
    "* - `mulogSe_NN`, `mulogSh_NN`\n",
    "  - Log SDF drifts for expert and household\n",
    "  - $-r_t S_t^e$, $-r_t S_t^h$\n",
    "* - `sigmalogSe_NN`, `sigmalogSh_NN`\n",
    "  - Log SDF diffusions for expert and household\n",
    "  - $-S_t^e \\pi_t^e$, $-S_t^h \\pi_t^h$\n",
    "* - `mulogCe_NN`, `mulogCh_NN`\n",
    "  - Log consumption drifts for expert and household\n",
    "  - $\\hat{\\mu}_c^e$, $\\hat{\\mu}_c^h$\n",
    "* - `sigmalogCe_NN`, `sigmalogCh_NN`\n",
    "  - Log consumption diffusions for expert and household\n",
    "  - $\\sigma_c^e$, $\\sigma_c^h$\n",
    "* - `mulogC_NN`\n",
    "  - Log aggregate consumption drift\n",
    "  - $\\hat{\\mu}_c$\n",
    "* - `sigmalogC_NN`\n",
    "  - Log aggregate consumption diffusion\n",
    "  - $\\sigma_c$\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that a solution has been saved under the same parameters, the following code outputs the variables listed above. In addition, the `marginal_quantile_func_factory` function is called to save the above outputs evaluated at desired quantiles (e.g. $Z^2$ at median) for ease of plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 15:49:17.685366: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "os.chdir('src/4')\n",
    "from main_variable import main_var\n",
    "os.chdir('../..')\n",
    "\n",
    "main_var(action_name, nWealth, nZ, nV, V_bar, sigma_K_norm, sigma_Z_norm, sigma_V_norm, wMin, wMax, chiUnderline, a_e, a_h, gamma_e, gamma_h, rho_e, rho_h, delta_e, delta_h, lambda_d, nu, shock_expo, n_layers, units, points_size, iter_num, seed, penalization, BFGS_maxiter, BFGS_maxfun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Plotting\n",
    "We can now plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "os.chdir('src/4')\n",
    "from plot import return_NN_solution\n",
    "os.chdir('../..')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", font_scale=1.13, rc={\"lines.linewidth\": 3.5})\n",
    "plt.rcParams['axes.formatter.useoffset'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load in the results using the same parameters as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = return_NN_solution(shock_expo=shock_expo, seed=seed, chiUnderline=chiUnderline, a_e=a_e, a_h=a_h, gamma_e=gamma_e, gamma_h=gamma_h, psi_e=rho_e, psi_h=rho_h, delta_e=delta_e, delta_h=delta_h, lambda_d=lambda_d, nu=nu, n_layers=n_layers, units=units, iter_num=iter_num, points_size=points_size, penalization=penalization, action_name=action_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide an example plot below. Notice that we use `results['eva_V_10']` and `results['eva_V_90']` to extract the variables of interest evaluated at $Z^1=0$ and $Z^2$ at its 10th and 90th percentiles, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(5,4))\n",
    "W_dense = np.unique(results['eva_V_50']['W'])\n",
    "W_sparse = np.unique(results['W'].values)\n",
    "sns.lineplot(x = W_dense, y = results['eva_V_10']['PiE_NN'][:,0], ax = ax)\n",
    "sns.lineplot(x = W_dense, y = results['eva_V_90']['PiE_NN'][:,0], ax = ax)\n",
    "ax2 = ax.twinx()\n",
    "sns.lineplot(x = W_sparse, y = results['dentW'].values, ax = ax2, ls='--', color='grey',lw=2.0, alpha=0.5)\n",
    "ax2.grid(False)\n",
    "ax2.set_yticks([])\n",
    "ax2.set_ylim([0,0.03])\n",
    "\n",
    "ax.set_xlim(0,1.0)\n",
    "ax.grid(False)\n",
    "ax.set_ylim([0.0,1.0])\n",
    "ax.set_xlabel('W', fontsize=15)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4.4 Finite Difference Method\n",
    "We employ a finite differences method from `mfrSuite` to solve Model IP from Section 5, which we cover briefly here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mfr.modelSoln as m\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model inputs are identical to the neural network solution above, except that: we abstract away from $Z^2$; we have to set $dt$ as our false-transient time-step; and some inputs have been moved inside the `main_solve.py` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "chiUnderline = 1.0\n",
    "a_e=0.0922\n",
    "a_h=0.0\n",
    "gamma_e = 4.0\n",
    "gamma_h=4.0\n",
    "delta_e=0.0115\n",
    "delta_h=0.01\n",
    "lambda_d=0.0\n",
    "rho_e=1.0\n",
    "rho_h=1.0\n",
    "nu=0.1\n",
    "dt = 0.1\n",
    "nWealth=180\n",
    "nZ=30\n",
    "shock_expo = 'upper_triangular'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envname",
   "language": "python",
   "name": "envname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
