

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>4 Heterogeneous Agents &#8212; Comparing DSGE Models</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'heterogeneous_agents';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="4 Elasticities" href="elasticities.html" />
    <link rel="prev" title="3 Two Capital Model" href="twocapital.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    <p class="title logo__title">Comparing DSGE Models</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="single_capital.html">1 Single Capital Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_ambiguity.html">2 Model Ambiguity</a></li>
<li class="toctree-l1"><a class="reference internal" href="twocapital.html">3 Two Capital Model</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">4 Heterogeneous Agents</a></li>

<li class="toctree-l1"><a class="reference internal" href="elasticities.html">4 Elasticities</a></li>


</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/heterogeneous_agents.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>4 Heterogeneous Agents</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">4 Heterogeneous Agents</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#solution-overview">Solution Overview</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-architecture">Model Architecture</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training">Training</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-parameters">Model Parameters</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#finite-difference-method">Finite Difference Method</a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="heterogeneous-agents">
<h1>4 Heterogeneous Agents<a class="headerlink" href="#heterogeneous-agents" title="Permalink to this heading">#</a></h1>
<p>Consider the environment in section 5. We need to solve the following:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \begin{split}
    {L}^e_{HJB} \left(v^e, v^h, \kappa, \chi;x \right) &amp;= \frac{\rho_e}{1-\rho_e} \delta_e^{1 / \rho_e} \exp\left[({1- \frac{1}{\rho_e}})v^e)\right]-\frac{\delta_e}{1-\rho_e}+r\\&amp;+\frac{1}{2 \gamma_e} \frac{\left(\Delta^e+\pi^h \cdot \sigma_R\right)^2}{\left\|\sigma_R\right\|^2}
+\left[\mu_X+\frac{1-\gamma_e}{\gamma_e}\left(\frac{\Delta^e+\pi^h \cdot \sigma_R}{\left\|\sigma_R\right\|^2}\right) \sigma_X \sigma_R\right] \cdot \partial_X v^e \\
&amp;+\frac{1}{2}\left[\operatorname{tr}\left(\sigma_X^{\prime} \partial_{xx^{\prime}} v^e \sigma_X\right)+\frac{1-\gamma_e}{\gamma_e}\left(\sigma_X^{\prime} \partial_x v_e\right)^{\prime}\left[\gamma_e \mathbb{I}_d+\left(1-\gamma_e\right) \frac{\sigma_R \sigma_R^{\prime}}{\left\|\sigma_R\right\|^2}\right] \sigma_X^{\prime} \partial_x v^e\right]= 0 
\end{split}\\
\begin{split}
    {L}^h_{HJB} \left(v^e, v^h, \kappa, \chi;x \right) &amp;=\frac{\rho_h}{1-\rho_h} \delta_h^{1 / \rho_h}  \exp\left[({1- \frac{1}{\rho_h}})v^h)\right]-\frac{\delta_h}{1-\rho_h}+r+\frac{1}{2 \gamma_h}\|\pi^h\|^2\\&amp;+\left[\mu_X+\frac{1-\gamma_h}{\gamma_h} \sigma_X \pi^h\right] \cdot \partial_x v^h +\frac{1}{2}\left[\operatorname{tr}\left(\sigma_X^{\prime} \partial_{xx^{\prime}} v^h \sigma_X\right)+\frac{1-\gamma_h}{\gamma_h}\left\|\sigma_X^{\prime} \partial_x v^h\right\|^2\right]=0\end{split} \\
\begin{split}
    {L}_{\kappa} \left(v^e, v^h,\kappa, \chi;x \right) &amp;= \min\Big\{ 1 - \kappa, \, w\gamma_h (1-\chi\kappa) | \sigma_R |^2 - (1-w) \gamma_e \chi \kappa | \sigma_R |^2  \\
	\qquad &amp;+ w(1-w) \frac{\alpha_e - \alpha_h}{\underline{\chi} q} + w(1-w) \left( \sigma_x \sigma_R \right) \cdot \left[ (\gamma_h-1)\partial_x \upsilon^h -  (\gamma_e-1)\partial_x \upsilon^e \right] \Big\} = 0\\
\end{split} \\
\begin{split}
    {L}_{\chi} \left(v^e, v^h, \kappa, \chi;x \right) &amp;= \min\Big\{ \chi - \underline{\chi}, \, \Big[ ((1-w)\gamma_e + w\gamma_h) | D_{z} |^2 + (\partial_w \log q) D_{\upsilon,z} - D_{\upsilon,w} \Big](\chi - w) \\
 \quad &amp;+ w(1-w) (\gamma_e - \gamma_h) | D_{z} |^2 - D_{\upsilon,z} \Big\} = 0
\end{split}
\end{align*}\]</div>
<p>Where:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
 D_{z} &amp;\doteq \sqrt{z_2}\sigma_k + \sigma_{z}' \partial_{z} \log q \\
 D_{\upsilon,w} &amp;\doteq w(1-w) | D_{z} |^2 \partial_w  \big[ (\gamma_h - 1) \upsilon^h - (\gamma_e - 1)\upsilon^e \big] \\
 D_{\upsilon,z} &amp;\doteq w(1-w) \left(\sigma_{z}D_{z} \right) \cdot \partial_{z} \big[ (\gamma_h - 1) \upsilon^h - (\gamma_e - 1)\upsilon^e  \big]
\end{align*}\]</div>
<p>Since <span class="math notranslate nohighlight">\(\chi\)</span> can be solved algebraically, we solve (1) to (3).</p>
<section id="solution-overview">
<h2>Solution Overview<a class="headerlink" href="#solution-overview" title="Permalink to this heading">#</a></h2>
<section id="model-architecture">
<h3>Model Architecture<a class="headerlink" href="#model-architecture" title="Permalink to this heading">#</a></h3>
<p>We modify the <code class="docutils literal notranslate"><span class="pre">DeepGalerkinMethod</span></code> code from https://github.com/alialaradi/DeepGalerkinMethod. We construct an object <code class="docutils literal notranslate"><span class="pre">sim_NN</span></code> of class <code class="docutils literal notranslate"><span class="pre">DGMNet</span></code> with the following hyperparameters:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Input</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Parameter used in paper</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">n_layers</span></code></p></td>
<td><p>Number of layers</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">units</span></code></p></td>
<td><p>Number of neurons in each layer</p></td>
<td><p>16</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">input_dim</span></code></p></td>
<td><p>Dimension of input into first layer</p></td>
<td><p>3 (This should be the same as the number of states)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">activation</span></code></p></td>
<td><p>Activation function for all layers except the last</p></td>
<td><p>tanh</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">final_activation</span></code></p></td>
<td><p>Activation function for final layer</p></td>
<td><p>Identity function for first two dimensions; sigmoid for third dimension. This is so that…</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">seed</span></code></p></td>
<td><p>Seed for weight and bias initialization</p></td>
<td><p>256</p></td>
</tr>
</tbody>
</table>
<p>We use a Glorot normal initializer to initialize weights and a Glorot uniform initializer to initialize the biases.</p>
</section>
<section id="training">
<h3>Training<a class="headerlink" href="#training" title="Permalink to this heading">#</a></h3>
<p>The training set is constructed by drawing uniformly from the three-dimensional cube bounded by [<code class="docutils literal notranslate"><span class="pre">wMin</span></code>,<code class="docutils literal notranslate"><span class="pre">zMin</span></code>,<code class="docutils literal notranslate"><span class="pre">vMin</span></code>] and [<code class="docutils literal notranslate"><span class="pre">wMax</span></code>,<code class="docutils literal notranslate"><span class="pre">zMax</span></code>,<code class="docutils literal notranslate"><span class="pre">vMax</span></code>]. The loss function is given by the mean squared error of <span class="math notranslate nohighlight">\(L\)</span>, where:</p>
<div class="math notranslate nohighlight">
\[
L = {L}^e_{HJB} + {L}^h_{HJB} + p{L}_{\kappa}
\]</div>
<p>Where <span class="math notranslate nohighlight">\(p\)</span> is a penalization parameter. We compute gradients using <code class="docutils literal notranslate"><span class="pre">tf.GradientTape</span></code> and use an <code class="docutils literal notranslate"><span class="pre">L-BFGS-B</span></code> solver. The full list of parameters for the training stage are:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Input</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Parameter used in paper</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">points_size</span></code></p></td>
<td><p>Determines the <code class="docutils literal notranslate"><span class="pre">batchSize</span></code>, which is <span class="math notranslate nohighlight">\(2^x\)</span> where <span class="math notranslate nohighlight">\(x\)</span> is <code class="docutils literal notranslate"><span class="pre">points_size</span></code>. Batch size is the number of training samples in each epoch</p></td>
<td><p>10</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">iter_num</span></code></p></td>
<td><p>Number of epochs, i.e. the number of complete passes through the training set</p></td>
<td><p>5</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">penalization</span></code></p></td>
<td><p>Penalty for violating <span class="math notranslate nohighlight">\(\kappa\)</span> constraint</p></td>
<td><p>10000</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">seed</span></code></p></td>
<td><p>Seed for drawing uniform samples</p></td>
<td><p>256 (same as seed for initialization)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">max_iter</span></code></p></td>
<td><p>Maximum number of L-BFGS-B iterations (number of times parameters are updated) per epoch</p></td>
<td><p>100</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">maxfun</span></code></p></td>
<td><p>Maximum number of function evaluations per epoch</p></td>
<td><p>100</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">maxcor</span></code></p></td>
<td><p>The maximum number of variable metric corrections used to define the limited memory matrix used to compute the Hessian per epoch</p></td>
<td><p>100</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">maxls</span></code></p></td>
<td><p>Maximum number of line search steps per iteration used to find the optimal step-size</p></td>
<td><p>100</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">gtol</span></code></p></td>
<td><p>Iteration will stop when <span class="math notranslate nohighlight">\(\max|proj(g_i)| \leq\)</span> <code class="docutils literal notranslate"><span class="pre">gtol</span></code> for each entry <span class="math notranslate nohighlight">\(i\)</span> of the (projected) gradient vector</p></td>
<td><p>Machine epsilon for float64 (~<span class="math notranslate nohighlight">\(2^{-16}\)</span>)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">ftol</span></code></p></td>
<td><p>Iteration will stop when <span class="math notranslate nohighlight">\(\frac{L^k - L^{k+1}}{\max{|L^k|,|L^{k+1}|,1}} \leq\)</span> <code class="docutils literal notranslate"><span class="pre">ftol</span></code></p></td>
<td><p>Machine epsilon for float64 (~<span class="math notranslate nohighlight">\(2^{-16}\)</span>)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">tolerance</span></code></p></td>
<td><p>Iteration will stop when, after fully completing an epoch, <span class="math notranslate nohighlight">\(L\)</span> is less than <code class="docutils literal notranslate"><span class="pre">tolerance</span></code></p></td>
<td><p><span class="math notranslate nohighlight">\(10^{-5}\)</span></p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="model-parameters">
<h2>Model Parameters<a class="headerlink" href="#model-parameters" title="Permalink to this heading">#</a></h2>
<p>We also need to set model parameters. These will vary depending on the environment chosen from Section 5.1. By default, the following parameters are allowed as inputs to <code class="docutils literal notranslate"><span class="pre">main_BFGS</span></code>:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Input</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Parameter used in paper</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">chiUnderline</span></code></p></td>
<td><p>Skin-in-the-game constraint</p></td>
<td><p><span class="math notranslate nohighlight">\(\underline{\chi}\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">gamma_e</span></code>, <code class="docutils literal notranslate"><span class="pre">gamma_h</span></code></p></td>
<td><p>Expert and household uncertainty aversion</p></td>
<td><p><span class="math notranslate nohighlight">\(\gamma_e, \gamma_h\)</span></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">a_e</span></code>, <code class="docutils literal notranslate"><span class="pre">a_h</span></code></p></td>
<td><p>Expert and household productivity</p></td>
<td><p><span class="math notranslate nohighlight">\(\alpha_e, \alpha_h\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">delta_e</span></code>,<code class="docutils literal notranslate"><span class="pre">delta_h</span></code></p></td>
<td><p>Expert and household discount rate</p></td>
<td><p><span class="math notranslate nohighlight">\(\delta_e, \delta_h\)</span></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">rho_e</span></code>,<code class="docutils literal notranslate"><span class="pre">rho_h</span></code></p></td>
<td><p>Expert and household inverse of IES</p></td>
<td><p><span class="math notranslate nohighlight">\(\rho_e, \rho_h\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">lambda_d</span></code></p></td>
<td><p>Birth/death rate</p></td>
<td><p><span class="math notranslate nohighlight">\(\lambda_d\)</span></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">nu</span></code></p></td>
<td><p>Fraction of newborns which are experts</p></td>
<td><p><span class="math notranslate nohighlight">\(\nu\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">V_bar</span></code></p></td>
<td><p>Mean of <span class="math notranslate nohighlight">\(Z_2\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\mu_2\)</span></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">sigma_K_norm</span></code>, <code class="docutils literal notranslate"><span class="pre">sigma_Z_norm</span></code>, <code class="docutils literal notranslate"><span class="pre">sigma_V_norm</span></code></p></td>
<td><p>Normalization for variances; these are multiplied by the covariance matrix specified in <code class="docutils literal notranslate"><span class="pre">utils_para</span></code> to yield <span class="math notranslate nohighlight">\(\sigma_k, \sigma_1, \sigma2\)</span></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">wMin</span></code>, <code class="docutils literal notranslate"><span class="pre">wMax</span></code></p></td>
<td><p>Bounds for training set for <span class="math notranslate nohighlight">\(W\)</span>; the corresponding bounds for <span class="math notranslate nohighlight">\(Z_1\)</span> and <span class="math notranslate nohighlight">\(Z_2\)</span> can be edited in <code class="docutils literal notranslate"><span class="pre">utils_para</span></code></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">nWealth</span></code>, <code class="docutils literal notranslate"><span class="pre">nZ</span></code>, <code class="docutils literal notranslate"><span class="pre">nV</span></code></p></td>
<td><p>Number of gridpoints for each state variable; this does not have any effect on the solution but will determine the evaluation of variables of interest using the solution at a later step</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">shock_expo</span></code></p></td>
<td><p>Determines whether the shock exposure matrix is “upper_triangular” or “lower_triangular”</p></td>
<td></td>
</tr>
</tbody>
</table>
<p>In addition, the following parameters can be edited in the <code class="docutils literal notranslate"><span class="pre">utils_para</span></code> file. They do not vary across the models explored in the paper, but the user may wish to explore their own variations.</p>
<p>We can build and train the neural network as follows. First, we import libraries:</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span> 
<span class="kn">import</span> <span class="nn">time</span> 
<span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s2">&quot;src/4&quot;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">main_BFGS</span> <span class="kn">import</span> <span class="n">main</span>
<span class="kn">from</span> <span class="nn">utils_para</span> <span class="kn">import</span> <span class="n">setModelParameters</span>
<span class="kn">from</span> <span class="nn">utils_training</span> <span class="kn">import</span> <span class="n">training_step_BFGS</span>
<span class="kn">from</span> <span class="nn">utils_DGM</span> <span class="kn">import</span> <span class="n">DGMNet</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s2">&quot;../..&quot;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">get_logger</span><span class="p">()</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="s1">&#39;ERROR&#39;</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set_visible_devices</span><span class="p">([],</span> <span class="s1">&#39;GPU&#39;</span><span class="p">)</span> <span class="c1"># To enable GPU acceleration, comment out this line and ensure CUDA and cuDNN libraries are properly installed</span>
</pre></div>
</div>
</div>
<details class="hide below-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell output</span>
<span class="expanded">Hide code cell output</span>
</summary>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024-08-28 13:19:02.969807: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-08-28 13:19:05.178721: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-08-28 13:19:06.389192: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libcudart.so.11.0&#39;; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/slurm-current-el8-x86_64/lib
2024-08-28 13:19:06.389212: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-08-28 13:19:06.683674: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-08-28 13:19:17.699752: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libnvinfer.so.7&#39;; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/slurm-current-el8-x86_64/lib
2024-08-28 13:19:17.699843: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libnvinfer_plugin.so.7&#39;; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/slurm-current-el8-x86_64/lib
2024-08-28 13:19:17.699849: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2024-08-28 13:19:32.240512: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libcuda.so.1&#39;; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/slurm-current-el8-x86_64/lib
2024-08-28 13:19:32.240561: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)
2024-08-28 13:19:32.240578: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (midway3-login3.rcc.local): /proc/driver/nvidia/version does not exist
</pre></div>
</div>
</div>
</details>
</div>
<p>Next, we set the model parameters and hyperparameters. In the following example, we have used a variant of Model RF.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chiUnderline</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">gamma_e</span> <span class="o">=</span> <span class="mf">4.0</span>
<span class="n">a_e</span><span class="o">=</span><span class="mf">0.0922</span>
<span class="n">a_h</span><span class="o">=</span><span class="mf">0.0</span>
<span class="n">gamma_h</span><span class="o">=</span><span class="mf">4.0</span>
<span class="n">delta_e</span><span class="o">=</span><span class="mf">0.0115</span>
<span class="n">delta_h</span><span class="o">=</span><span class="mf">0.01</span>
<span class="n">lambda_d</span><span class="o">=</span><span class="mf">0.0</span>
<span class="n">rho_e</span><span class="o">=</span><span class="mf">1.0</span>
<span class="n">rho_h</span><span class="o">=</span><span class="mf">1.0</span>
<span class="n">nu</span><span class="o">=</span><span class="mf">0.1</span>

<span class="n">V_bar</span><span class="o">=</span><span class="mf">0.0000063030303030303026</span>
<span class="n">sigma_K_norm</span><span class="o">=</span><span class="mf">3.1707442821755683</span>
<span class="n">sigma_Z_norm</span><span class="o">=</span><span class="mf">19.835431735873996</span>
<span class="n">sigma_V_norm</span><span class="o">=</span><span class="mf">0.0010882177801089308</span>
<span class="n">wMin</span><span class="o">=</span><span class="mf">0.01</span>
<span class="n">wMax</span><span class="o">=</span><span class="mf">0.99</span>

<span class="n">nWealth</span><span class="o">=</span><span class="mi">180</span>
<span class="n">nZ</span><span class="o">=</span><span class="mi">30</span>
<span class="n">nV</span><span class="o">=</span><span class="mi">30</span>

<span class="n">seed_</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">)</span>
<span class="n">n_layers_</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">units_</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span>
<span class="n">points_size_</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">iter_num_</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">penalization</span><span class="o">=</span><span class="mi">10000</span>

<span class="n">BFGSmaxiter</span><span class="o">=</span><span class="mi">100</span>
<span class="n">BFGSmaxfun</span><span class="o">=</span><span class="mi">100</span>
<span class="n">action_name</span> <span class="o">=</span> <span class="s1">&#39;test&#39;</span>

<span class="n">seed</span><span class="o">=</span><span class="mi">256</span>
<span class="n">n_layers</span><span class="o">=</span><span class="mi">2</span>
<span class="n">units</span><span class="o">=</span><span class="mi">16</span>
<span class="n">points_size</span><span class="o">=</span><span class="mi">10</span>
<span class="n">iter_num</span><span class="o">=</span><span class="mi">5</span>
<span class="n">penalization</span><span class="o">=</span><span class="mi">10000</span>
<span class="n">BFGS_maxiter</span><span class="o">=</span><span class="mi">100</span>
<span class="n">BFGS_maxfun</span><span class="o">=</span><span class="mi">100</span>
<span class="n">shock_expo</span> <span class="o">=</span> <span class="s1">&#39;upper_triangular&#39;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">main</span><span class="p">(</span><span class="n">action_name</span><span class="p">,</span> <span class="n">nWealth</span><span class="p">,</span> <span class="n">nZ</span><span class="p">,</span> <span class="n">nV</span><span class="p">,</span> <span class="n">V_bar</span><span class="p">,</span> <span class="n">sigma_K_norm</span><span class="p">,</span> <span class="n">sigma_Z_norm</span><span class="p">,</span> <span class="n">sigma_V_norm</span><span class="p">,</span> <span class="n">wMin</span><span class="p">,</span> <span class="n">wMax</span><span class="p">,</span> <span class="n">chiUnderline</span><span class="p">,</span> <span class="n">a_e</span><span class="p">,</span> <span class="n">a_h</span><span class="p">,</span> <span class="n">gamma_e</span><span class="p">,</span> <span class="n">gamma_h</span><span class="p">,</span> <span class="n">rho_e</span><span class="p">,</span> <span class="n">rho_h</span><span class="p">,</span> <span class="n">delta_e</span><span class="p">,</span> <span class="n">delta_h</span><span class="p">,</span> <span class="n">lambda_d</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">shock_expo</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">points_size</span><span class="p">,</span> <span class="n">iter_num</span><span class="p">,</span> <span class="n">units</span><span class="p">,</span> <span class="n">seed</span><span class="p">,</span> <span class="n">penalization</span><span class="p">,</span> <span class="n">BFGS_maxiter</span><span class="p">,</span> <span class="n">BFGS_maxfun</span><span class="p">)</span>
</pre></div>
</div>
</div>
<details class="hide below-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell output</span>
<span class="expanded">Hide code cell output</span>
</summary>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024-08-28 11:53:42.950166: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training Batch 1
WARNING: AutoGraph could not transform &lt;bound method Socket.send of &lt;zmq.Socket(zmq.PUSH) at 0x7fe5e04964c0&gt;&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
BFGS Iter: 1 loss: 2.4774472703476573
BFGS Iter: 2 loss: 1.1956006049934733
BFGS Iter: 3 loss: 1.1512525155491342
BFGS Iter: 4 loss: 1.1129767803662238
BFGS Iter: 5 loss: 0.66527442628344491
BFGS Iter: 6 loss: 0.19045107418377538
BFGS Iter: 7 loss: 0.14912483949077682
BFGS Iter: 8 loss: 13735.611871315654
BFGS Iter: 9 loss: 6.1972373051936556
BFGS Iter: 10 loss: 0.1596903342691938
BFGS Iter: 11 loss: 0.13320460614263718
BFGS Iter: 12 loss: 0.10059469459515527
BFGS Iter: 13 loss: 0.07474686259589601
BFGS Iter: 14 loss: 0.062933798120950624
BFGS Iter: 15 loss: 0.055086244251407859
BFGS Iter: 16 loss: 0.050427814352636088
BFGS Iter: 17 loss: 0.046813373478503034
BFGS Iter: 18 loss: 0.045500246076412468
BFGS Iter: 19 loss: 0.04387517781687314
BFGS Iter: 20 loss: 0.091107656580451252
BFGS Iter: 21 loss: 0.0342036619069961
BFGS Iter: 22 loss: 0.031755537839112072
BFGS Iter: 23 loss: 0.024450823213388515
BFGS Iter: 24 loss: 0.072173266097987437
BFGS Iter: 25 loss: 0.02098351616409698
BFGS Iter: 26 loss: 0.28981045467710354
BFGS Iter: 27 loss: 0.011887332558140942
BFGS Iter: 28 loss: 0.037647404339732675
BFGS Iter: 29 loss: 0.00902718593900408
BFGS Iter: 30 loss: 0.0083789179332656033
BFGS Iter: 31 loss: 0.0043935143303938324
BFGS Iter: 32 loss: 0.0019368788908450379
BFGS Iter: 33 loss: 0.0019099897959955852
BFGS Iter: 34 loss: 0.0014738935433658501
BFGS Iter: 35 loss: 0.0011593717042880736
BFGS Iter: 36 loss: 0.000908164038048691
BFGS Iter: 37 loss: 0.00075176866092291112
BFGS Iter: 38 loss: 0.00054805996634202836
BFGS Iter: 39 loss: 0.00051959944474631512
BFGS Iter: 40 loss: 0.00045225661397642575
BFGS Iter: 41 loss: 0.0004325621978176222
BFGS Iter: 42 loss: 0.00035683277983640077
BFGS Iter: 43 loss: 0.0003424233979344597
BFGS Iter: 44 loss: 0.000329914761644039
BFGS Iter: 45 loss: 0.00032742520569724423
BFGS Iter: 46 loss: 0.00032544636316967935
BFGS Iter: 47 loss: 0.00031352262369962976
BFGS Iter: 48 loss: 0.00030225915501465875
BFGS Iter: 49 loss: 0.00027523893339239481
BFGS Iter: 50 loss: 0.00025455428426839213
BFGS Iter: 51 loss: 0.00024578583089963576
BFGS Iter: 52 loss: 0.00024285342973901885
BFGS Iter: 53 loss: 0.00023994461890596813
BFGS Iter: 54 loss: 0.00023861381196568589
BFGS Iter: 55 loss: 0.00023673930657093907
BFGS Iter: 56 loss: 0.00023398271997321796
BFGS Iter: 57 loss: 0.00022724885180655128
BFGS Iter: 58 loss: 0.00021661176044998102
BFGS Iter: 59 loss: 0.00020958772227023991
BFGS Iter: 60 loss: 0.0002064656223563504
BFGS Iter: 61 loss: 0.00019922072684694085
BFGS Iter: 62 loss: 0.00017271409691762808
BFGS Iter: 63 loss: 0.00014857614158382586
BFGS Iter: 64 loss: 0.00024695471443224689
BFGS Iter: 65 loss: 0.00013835145106131489
BFGS Iter: 66 loss: 0.00013451456369301468
BFGS Iter: 67 loss: 0.00013161012137018582
BFGS Iter: 68 loss: 0.00012613454285588814
BFGS Iter: 69 loss: 0.00012144641553965568
BFGS Iter: 70 loss: 0.00011831696831485425
BFGS Iter: 71 loss: 0.00011658986349170722
BFGS Iter: 72 loss: 0.00011495065149315101
BFGS Iter: 73 loss: 0.00011182459290387857
BFGS Iter: 74 loss: 0.00010701676672256478
BFGS Iter: 75 loss: 0.00010168748247379941
BFGS Iter: 76 loss: 9.8110563654184735e-05
BFGS Iter: 77 loss: 9.7013183430058578e-05
BFGS Iter: 78 loss: 9.6442862813273759e-05
BFGS Iter: 79 loss: 9.5818499871771386e-05
BFGS Iter: 80 loss: 9.3725689390033315e-05
BFGS Iter: 81 loss: 9.0592041217983809e-05
BFGS Iter: 82 loss: 8.4723022281452625e-05
BFGS Iter: 83 loss: 7.8949903997356063e-05
BFGS Iter: 84 loss: 7.70492580908571e-05
BFGS Iter: 85 loss: 7.6541986492635109e-05
BFGS Iter: 86 loss: 7.6155678845069355e-05
BFGS Iter: 87 loss: 7.5955811036532e-05
BFGS Iter: 88 loss: 7.5641444375039929e-05
BFGS Iter: 89 loss: 7.4598212022948033e-05
BFGS Iter: 90 loss: 6.929043309298374e-05
BFGS Iter: 91 loss: 5.9968128687644348e-05
BFGS Iter: 92 loss: 5.5785700736942215e-05
BFGS Iter: 93 loss: 5.2484043662533347e-05
BFGS Iter: 94 loss: 5.0133791024322124e-05
BFGS Iter: 95 loss: 4.8850315791665443e-05
BFGS Iter: 96 loss: 4.7110570759746623e-05
BFGS Iter: 97 loss: 4.491745003882522e-05
BFGS Iter: 98 loss: 4.0061435089068928e-05
BFGS Iter: 99 loss: 3.613962132748868e-05
BFGS Iter: 100 loss: 3.51466198559229e-05
BFGS Iter: 101 loss: 3.4883861920420573e-05
Elapsed time 38.9414 sec
Training Batch 2
BFGS Iter: 1 loss: 3.2853896971848968e-05
BFGS Iter: 2 loss: 0.019707537745072244
BFGS Iter: 3 loss: 0.00014041080336993437
BFGS Iter: 4 loss: 3.1974377718675872e-05
BFGS Iter: 5 loss: 3.1825184390630736e-05
BFGS Iter: 6 loss: 3.1344167734114741e-05
BFGS Iter: 7 loss: 3.1252179104972564e-05
BFGS Iter: 8 loss: 3.0416883028541236e-05
BFGS Iter: 9 loss: 2.97514132047265e-05
BFGS Iter: 10 loss: 2.906501017422695e-05
BFGS Iter: 11 loss: 2.8818583544234104e-05
BFGS Iter: 12 loss: 2.873178819948239e-05
BFGS Iter: 13 loss: 2.8648501538548452e-05
BFGS Iter: 14 loss: 2.8449005933157758e-05
BFGS Iter: 15 loss: 2.8064555371744166e-05
BFGS Iter: 16 loss: 2.7536057681507427e-05
BFGS Iter: 17 loss: 2.703641185822243e-05
BFGS Iter: 18 loss: 2.6687933523042895e-05
BFGS Iter: 19 loss: 2.6522887393995814e-05
BFGS Iter: 20 loss: 2.6264218254959419e-05
BFGS Iter: 21 loss: 2.591644718390245e-05
BFGS Iter: 22 loss: 2.4977123780294386e-05
BFGS Iter: 23 loss: 2.3383280580777118e-05
BFGS Iter: 24 loss: 2.2759879544202166e-05
BFGS Iter: 25 loss: 2.2252896993315572e-05
BFGS Iter: 26 loss: 2.1371535914795528e-05
BFGS Iter: 27 loss: 2.0839626254889541e-05
BFGS Iter: 28 loss: 2.0777584427760023e-05
BFGS Iter: 29 loss: 2.0736604962744527e-05
BFGS Iter: 30 loss: 2.0705036193386124e-05
BFGS Iter: 31 loss: 2.0655092647324191e-05
BFGS Iter: 32 loss: 2.0598914750422025e-05
BFGS Iter: 33 loss: 2.0468158345696189e-05
BFGS Iter: 34 loss: 2.0224766860300472e-05
BFGS Iter: 35 loss: 1.9839248942125531e-05
BFGS Iter: 36 loss: 1.9341026918287342e-05
BFGS Iter: 37 loss: 1.8884423073158643e-05
BFGS Iter: 38 loss: 1.8702716459971356e-05
BFGS Iter: 39 loss: 1.8560172826039611e-05
BFGS Iter: 40 loss: 1.8276066722155523e-05
BFGS Iter: 41 loss: 1.7623510034851014e-05
BFGS Iter: 42 loss: 1.6761181733420085e-05
BFGS Iter: 43 loss: 1.6166916889031392e-05
BFGS Iter: 44 loss: 1.5472076204676365e-05
BFGS Iter: 45 loss: 1.5024891047283445e-05
BFGS Iter: 46 loss: 1.4355291727712163e-05
BFGS Iter: 47 loss: 1.3642639885382408e-05
BFGS Iter: 48 loss: 1.3508537886352953e-05
BFGS Iter: 49 loss: 1.3444851352247259e-05
BFGS Iter: 50 loss: 1.3359903255302055e-05
BFGS Iter: 51 loss: 1.3272913830301804e-05
BFGS Iter: 52 loss: 1.3207987129916955e-05
BFGS Iter: 53 loss: 1.3101230685461094e-05
BFGS Iter: 54 loss: 1.2988284528412209e-05
BFGS Iter: 55 loss: 1.282990171102536e-05
BFGS Iter: 56 loss: 1.2712032288942737e-05
BFGS Iter: 57 loss: 1.2674735833415232e-05
BFGS Iter: 58 loss: 1.2663329186623378e-05
BFGS Iter: 59 loss: 1.2650315702993225e-05
BFGS Iter: 60 loss: 1.2623578282506827e-05
BFGS Iter: 61 loss: 1.2577814294733134e-05
BFGS Iter: 62 loss: 1.2547208683358239e-05
BFGS Iter: 63 loss: 1.2523502020011372e-05
BFGS Iter: 64 loss: 1.2501757713314936e-05
BFGS Iter: 65 loss: 1.2418363606262223e-05
BFGS Iter: 66 loss: 1.2253280554965201e-05
BFGS Iter: 67 loss: 1.2195432558519506e-05
BFGS Iter: 68 loss: 1.2185728612095706e-05
BFGS Iter: 69 loss: 1.2172212591885034e-05
BFGS Iter: 70 loss: 1.2168082534604752e-05
BFGS Iter: 71 loss: 1.216592102061464e-05
BFGS Iter: 72 loss: 1.2160875524338406e-05
BFGS Iter: 73 loss: 1.2133819802866951e-05
BFGS Iter: 74 loss: 1.2109716961644602e-05
BFGS Iter: 75 loss: 1.2087067091338671e-05
BFGS Iter: 76 loss: 1.2076558024284849e-05
BFGS Iter: 77 loss: 1.2066996255622948e-05
BFGS Iter: 78 loss: 1.2053154613077278e-05
BFGS Iter: 79 loss: 1.203797942341931e-05
BFGS Iter: 80 loss: 1.2016844012736538e-05
BFGS Iter: 81 loss: 1.200139477497608e-05
BFGS Iter: 82 loss: 1.1988520697403073e-05
BFGS Iter: 83 loss: 1.198157664545267e-05
BFGS Iter: 84 loss: 1.1978585181529594e-05
BFGS Iter: 85 loss: 1.1966552352106392e-05
BFGS Iter: 86 loss: 1.1956102387720503e-05
BFGS Iter: 87 loss: 1.1935969329296331e-05
BFGS Iter: 88 loss: 1.1921091735959954e-05
BFGS Iter: 89 loss: 1.1912455188382755e-05
BFGS Iter: 90 loss: 1.191066868206912e-05
BFGS Iter: 91 loss: 1.1910354321870175e-05
BFGS Iter: 92 loss: 1.1909990710776239e-05
BFGS Iter: 93 loss: 1.1909094263289071e-05
BFGS Iter: 94 loss: 1.1906607107549928e-05
BFGS Iter: 95 loss: 1.1900758789743032e-05
BFGS Iter: 96 loss: 1.1886762849391672e-05
BFGS Iter: 97 loss: 1.1866360902097644e-05
BFGS Iter: 98 loss: 1.1851912471258075e-05
BFGS Iter: 99 loss: 1.1829654621967488e-05
BFGS Iter: 100 loss: 1.181186005704434e-05
BFGS Iter: 101 loss: 1.1808721580096721e-05
Elapsed time 13.4273 sec
Training Batch 3
BFGS Iter: 1 loss: 1.331064116882083e-05
BFGS Iter: 2 loss: 0.06117408740760033
BFGS Iter: 3 loss: 1.6545090774307306e-05
BFGS Iter: 4 loss: 1.3233483451527528e-05
BFGS Iter: 5 loss: 1.3229861876555701e-05
BFGS Iter: 6 loss: 1.3220643103168207e-05
BFGS Iter: 7 loss: 1.3218023683495404e-05
BFGS Iter: 8 loss: 1.3192825006285791e-05
BFGS Iter: 9 loss: 1.3162709506410751e-05
BFGS Iter: 10 loss: 1.3122478405834297e-05
BFGS Iter: 11 loss: 1.3086652696287559e-05
BFGS Iter: 12 loss: 1.3066946734789399e-05
BFGS Iter: 13 loss: 1.30625645234478e-05
BFGS Iter: 14 loss: 1.3056600028652622e-05
BFGS Iter: 15 loss: 1.3041742751643852e-05
BFGS Iter: 16 loss: 1.302278511422033e-05
BFGS Iter: 17 loss: 1.3015263917683468e-05
BFGS Iter: 18 loss: 1.3010882437890982e-05
BFGS Iter: 19 loss: 1.3007174746827917e-05
BFGS Iter: 20 loss: 1.3003567895294272e-05
BFGS Iter: 21 loss: 1.2994063999200187e-05
BFGS Iter: 22 loss: 1.2976924536905825e-05
BFGS Iter: 23 loss: 1.2957821812855494e-05
BFGS Iter: 24 loss: 1.2945510229395388e-05
BFGS Iter: 25 loss: 1.2933797095940215e-05
BFGS Iter: 26 loss: 1.2924884708960356e-05
BFGS Iter: 27 loss: 1.2914824453347176e-05
BFGS Iter: 28 loss: 1.2907758553489387e-05
BFGS Iter: 29 loss: 1.2902529350726502e-05
BFGS Iter: 30 loss: 1.2892655423718043e-05
BFGS Iter: 31 loss: 1.2878869677871708e-05
BFGS Iter: 32 loss: 1.2855464224573348e-05
BFGS Iter: 33 loss: 1.2836326345029857e-05
BFGS Iter: 34 loss: 1.282503585884498e-05
BFGS Iter: 35 loss: 1.2819832876536658e-05
BFGS Iter: 36 loss: 1.2817327177132516e-05
BFGS Iter: 37 loss: 1.2814583416266755e-05
BFGS Iter: 38 loss: 1.2812970776046914e-05
BFGS Iter: 39 loss: 1.2811340914372243e-05
BFGS Iter: 40 loss: 1.2808473901933942e-05
BFGS Iter: 41 loss: 1.2804617061602693e-05
BFGS Iter: 42 loss: 1.2799461734615346e-05
BFGS Iter: 43 loss: 1.2791872909612326e-05
BFGS Iter: 44 loss: 1.2775845340300466e-05
BFGS Iter: 45 loss: 1.2767558545070499e-05
BFGS Iter: 46 loss: 1.2765786028034198e-05
BFGS Iter: 47 loss: 1.2765456915944788e-05
BFGS Iter: 48 loss: 1.2764954898250717e-05
BFGS Iter: 49 loss: 1.2763820297186977e-05
BFGS Iter: 50 loss: 1.2761370314026455e-05
BFGS Iter: 51 loss: 1.275633242947466e-05
BFGS Iter: 52 loss: 1.2748364647824511e-05
BFGS Iter: 53 loss: 1.2737479564954124e-05
BFGS Iter: 54 loss: 1.2731536537342279e-05
BFGS Iter: 55 loss: 1.2726402028368688e-05
BFGS Iter: 56 loss: 1.2724893055359673e-05
BFGS Iter: 57 loss: 1.2722910755738014e-05
BFGS Iter: 58 loss: 1.2719392273903786e-05
BFGS Iter: 59 loss: 1.2711735264065272e-05
BFGS Iter: 60 loss: 1.2704860674004855e-05
BFGS Iter: 61 loss: 1.27021993723173e-05
BFGS Iter: 62 loss: 1.2701273997595555e-05
BFGS Iter: 63 loss: 1.2701021816793273e-05
BFGS Iter: 64 loss: 1.2700517502319772e-05
BFGS Iter: 65 loss: 1.269903508238038e-05
BFGS Iter: 66 loss: 1.2697087291156104e-05
BFGS Iter: 67 loss: 1.2693290446662503e-05
BFGS Iter: 68 loss: 1.2687183746506989e-05
BFGS Iter: 69 loss: 1.2682668907493189e-05
BFGS Iter: 70 loss: 1.2679415896418426e-05
BFGS Iter: 71 loss: 1.2676845117611318e-05
BFGS Iter: 72 loss: 1.2673213507258254e-05
BFGS Iter: 73 loss: 1.2666559781308332e-05
BFGS Iter: 74 loss: 1.2656686082966439e-05
BFGS Iter: 75 loss: 1.2644999148520057e-05
BFGS Iter: 76 loss: 1.2635209939852263e-05
BFGS Iter: 77 loss: 1.2630498568379768e-05
BFGS Iter: 78 loss: 1.262936268884058e-05
BFGS Iter: 79 loss: 1.2628221954083415e-05
BFGS Iter: 80 loss: 1.2628029582622525e-05
BFGS Iter: 81 loss: 1.262792602962517e-05
BFGS Iter: 82 loss: 1.262772463638237e-05
BFGS Iter: 83 loss: 1.262706943312788e-05
BFGS Iter: 84 loss: 1.2624294992242655e-05
BFGS Iter: 85 loss: 1.2618450273525895e-05
BFGS Iter: 86 loss: 1.2609322074630907e-05
BFGS Iter: 87 loss: 1.2598401519292362e-05
BFGS Iter: 88 loss: 1.2590384564064844e-05
BFGS Iter: 89 loss: 1.2587779992697465e-05
BFGS Iter: 90 loss: 1.258765922461213e-05
BFGS Iter: 91 loss: 1.2587290535380229e-05
BFGS Iter: 92 loss: 1.2587197180692745e-05
BFGS Iter: 93 loss: 1.2586706782716528e-05
BFGS Iter: 94 loss: 1.2585824920184296e-05
BFGS Iter: 95 loss: 1.2583355677049011e-05
BFGS Iter: 96 loss: 1.257742418799933e-05
BFGS Iter: 97 loss: 1.2565273036975706e-05
BFGS Iter: 98 loss: 1.2548872096132877e-05
BFGS Iter: 99 loss: 1.2535809180398835e-05
BFGS Iter: 100 loss: 1.2530088247677251e-05
BFGS Iter: 101 loss: 1.2528984134717129e-05
Elapsed time 13.7815 sec
Training Batch 4
BFGS Iter: 1 loss: 1.2934253125994222e-05
BFGS Iter: 2 loss: 0.022237867180928024
BFGS Iter: 3 loss: 3.5087285345516575e-05
BFGS Iter: 4 loss: 1.2748799764896702e-05
BFGS Iter: 5 loss: 1.2684513583115664e-05
BFGS Iter: 6 loss: 1.249150200462084e-05
BFGS Iter: 7 loss: 1.2368280693659667e-05
BFGS Iter: 8 loss: 1.2363141064484407e-05
BFGS Iter: 9 loss: 1.2344596450679788e-05
BFGS Iter: 10 loss: 1.2244304824844164e-05
BFGS Iter: 11 loss: 1.2215863286743963e-05
BFGS Iter: 12 loss: 1.2205716259213079e-05
BFGS Iter: 13 loss: 1.2202306969429472e-05
BFGS Iter: 14 loss: 1.219602381087838e-05
BFGS Iter: 15 loss: 1.2183416717284681e-05
BFGS Iter: 16 loss: 1.216555188607241e-05
BFGS Iter: 17 loss: 1.213824387136914e-05
BFGS Iter: 18 loss: 1.2121873224964583e-05
BFGS Iter: 19 loss: 1.2114396371794193e-05
BFGS Iter: 20 loss: 1.2091100146216405e-05
BFGS Iter: 21 loss: 1.20618082017786e-05
BFGS Iter: 22 loss: 1.2024929276501241e-05
BFGS Iter: 23 loss: 1.2004709867961343e-05
BFGS Iter: 24 loss: 1.2000014343663818e-05
BFGS Iter: 25 loss: 1.1996822486851663e-05
BFGS Iter: 26 loss: 1.1989850270745779e-05
BFGS Iter: 27 loss: 1.1974217370844448e-05
BFGS Iter: 28 loss: 1.1946488450148227e-05
BFGS Iter: 29 loss: 1.1913115843031066e-05
BFGS Iter: 30 loss: 1.1894778447483723e-05
BFGS Iter: 31 loss: 1.18910343952307e-05
BFGS Iter: 32 loss: 1.1890089907808542e-05
BFGS Iter: 33 loss: 1.1888383677046635e-05
BFGS Iter: 34 loss: 1.1883279903485097e-05
BFGS Iter: 35 loss: 1.18726499949084e-05
BFGS Iter: 36 loss: 1.1855289160002535e-05
BFGS Iter: 37 loss: 1.182632836397997e-05
BFGS Iter: 38 loss: 1.1813207373814069e-05
BFGS Iter: 39 loss: 1.1810327741296157e-05
BFGS Iter: 40 loss: 1.1804946454478749e-05
BFGS Iter: 41 loss: 1.1799320112426194e-05
BFGS Iter: 42 loss: 1.1784198426799898e-05
BFGS Iter: 43 loss: 1.1769579908185478e-05
BFGS Iter: 44 loss: 1.1767728109488193e-05
BFGS Iter: 45 loss: 1.1766500347053901e-05
BFGS Iter: 46 loss: 1.1761919906735553e-05
BFGS Iter: 47 loss: 1.1739475105618486e-05
BFGS Iter: 48 loss: 1.1708020101422758e-05
BFGS Iter: 49 loss: 1.1670674598939108e-05
BFGS Iter: 50 loss: 1.1623827232351979e-05
BFGS Iter: 51 loss: 1.1605535208677066e-05
BFGS Iter: 52 loss: 1.1601464777961568e-05
BFGS Iter: 53 loss: 1.1597955390530642e-05
BFGS Iter: 54 loss: 1.1586662443935898e-05
BFGS Iter: 55 loss: 1.1580133780187473e-05
BFGS Iter: 56 loss: 1.156435494533015e-05
BFGS Iter: 57 loss: 1.1539723572476787e-05
BFGS Iter: 58 loss: 1.1532189883250412e-05
BFGS Iter: 59 loss: 1.1529285133376485e-05
BFGS Iter: 60 loss: 1.1528397670048011e-05
BFGS Iter: 61 loss: 1.1521689318842587e-05
BFGS Iter: 62 loss: 1.1508087374335811e-05
BFGS Iter: 63 loss: 1.1476676378203691e-05
BFGS Iter: 64 loss: 1.1445097641256559e-05
BFGS Iter: 65 loss: 1.1416397252667121e-05
BFGS Iter: 66 loss: 1.1400985805566946e-05
BFGS Iter: 67 loss: 1.139254947373997e-05
BFGS Iter: 68 loss: 1.1380127286031163e-05
BFGS Iter: 69 loss: 1.1367041867669604e-05
BFGS Iter: 70 loss: 1.1354795170612564e-05
BFGS Iter: 71 loss: 1.1350218161038208e-05
BFGS Iter: 72 loss: 1.1347431232098256e-05
BFGS Iter: 73 loss: 1.1342765436043796e-05
BFGS Iter: 74 loss: 1.1337951586426075e-05
BFGS Iter: 75 loss: 1.1326444235439111e-05
BFGS Iter: 76 loss: 1.1315133169016556e-05
BFGS Iter: 77 loss: 1.1305252551126212e-05
BFGS Iter: 78 loss: 1.1301318383477032e-05
BFGS Iter: 79 loss: 1.1299828189733894e-05
BFGS Iter: 80 loss: 1.1297910483081172e-05
BFGS Iter: 81 loss: 1.1294123159386268e-05
BFGS Iter: 82 loss: 1.1284997025994963e-05
BFGS Iter: 83 loss: 1.1272374146795017e-05
BFGS Iter: 84 loss: 1.1262237728419937e-05
BFGS Iter: 85 loss: 1.1254497290392012e-05
BFGS Iter: 86 loss: 1.1247674993836394e-05
BFGS Iter: 87 loss: 1.1241008582186026e-05
BFGS Iter: 88 loss: 1.1229533749776404e-05
BFGS Iter: 89 loss: 1.1223094868210285e-05
BFGS Iter: 90 loss: 1.1221029790459714e-05
BFGS Iter: 91 loss: 1.1220563854183987e-05
BFGS Iter: 92 loss: 1.1220395662515568e-05
BFGS Iter: 93 loss: 1.121967406397467e-05
BFGS Iter: 94 loss: 1.1215132161734005e-05
BFGS Iter: 95 loss: 1.1209151111831868e-05
BFGS Iter: 96 loss: 1.1197307803262909e-05
BFGS Iter: 97 loss: 1.1186821861820828e-05
BFGS Iter: 98 loss: 1.1181929521796944e-05
BFGS Iter: 99 loss: 1.1181207434858048e-05
BFGS Iter: 100 loss: 1.118102366166359e-05
BFGS Iter: 101 loss: 1.1180886294138432e-05
Elapsed time 13.1249 sec
Training Batch 5
BFGS Iter: 1 loss: 3.5371236143115144e-05
BFGS Iter: 2 loss: 0.14220276672329604
BFGS Iter: 3 loss: 0.0053646011810574365
BFGS Iter: 4 loss: 0.00031364060581301234
BFGS Iter: 5 loss: 1.8928635540105462e-05
BFGS Iter: 6 loss: 1.7790417724596251e-05
BFGS Iter: 7 loss: 1.5658651419098762e-05
BFGS Iter: 8 loss: 1.5400933235362e-05
BFGS Iter: 9 loss: 1.5387480853495626e-05
BFGS Iter: 10 loss: 1.5331273113404196e-05
BFGS Iter: 11 loss: 1.5229814501211383e-05
BFGS Iter: 12 loss: 1.4960227036595818e-05
BFGS Iter: 13 loss: 1.4468751921052961e-05
BFGS Iter: 14 loss: 1.3845158095502893e-05
BFGS Iter: 15 loss: 1.3403873135908949e-05
BFGS Iter: 16 loss: 1.3246065627405587e-05
BFGS Iter: 17 loss: 1.3221379859331613e-05
BFGS Iter: 18 loss: 1.3199607297060127e-05
BFGS Iter: 19 loss: 1.3144872604214214e-05
BFGS Iter: 20 loss: 1.3053734001415056e-05
BFGS Iter: 21 loss: 1.2796692896697949e-05
BFGS Iter: 22 loss: 1.2329643930171517e-05
BFGS Iter: 23 loss: 1.2196946630989999e-05
BFGS Iter: 24 loss: 1.2112374293463313e-05
BFGS Iter: 25 loss: 1.1995618308926672e-05
BFGS Iter: 26 loss: 1.192519068129695e-05
BFGS Iter: 27 loss: 1.1907527560263758e-05
BFGS Iter: 28 loss: 1.1872807374446712e-05
BFGS Iter: 29 loss: 1.186656525950388e-05
BFGS Iter: 30 loss: 1.1865108259411649e-05
BFGS Iter: 31 loss: 1.1863998629821241e-05
BFGS Iter: 32 loss: 1.1860723285461483e-05
BFGS Iter: 33 loss: 1.1853197029721009e-05
BFGS Iter: 34 loss: 1.1835622095321231e-05
BFGS Iter: 35 loss: 1.1803717724713043e-05
BFGS Iter: 36 loss: 1.1764876259997913e-05
BFGS Iter: 37 loss: 1.1739488157964466e-05
BFGS Iter: 38 loss: 1.173195844411259e-05
BFGS Iter: 39 loss: 1.1730718823954479e-05
BFGS Iter: 40 loss: 1.1729250216689364e-05
BFGS Iter: 41 loss: 1.172461525986897e-05
BFGS Iter: 42 loss: 1.1713365115901901e-05
BFGS Iter: 43 loss: 1.168818750167371e-05
BFGS Iter: 44 loss: 1.1644935853311753e-05
BFGS Iter: 45 loss: 1.159274261341498e-05
BFGS Iter: 46 loss: 1.1563088949500705e-05
BFGS Iter: 47 loss: 1.1556632573438674e-05
BFGS Iter: 48 loss: 1.1554112040634257e-05
BFGS Iter: 49 loss: 1.1549878581285814e-05
BFGS Iter: 50 loss: 1.1539610643148062e-05
BFGS Iter: 51 loss: 1.1522281942447986e-05
BFGS Iter: 52 loss: 1.149251415014182e-05
BFGS Iter: 53 loss: 1.1479392333423878e-05
BFGS Iter: 54 loss: 1.1475994363881961e-05
BFGS Iter: 55 loss: 1.1468372225899354e-05
BFGS Iter: 56 loss: 1.1456541320631684e-05
BFGS Iter: 57 loss: 1.1439399776759038e-05
BFGS Iter: 58 loss: 1.1410725492089062e-05
BFGS Iter: 59 loss: 1.1356054766756423e-05
BFGS Iter: 60 loss: 1.1330061545090437e-05
BFGS Iter: 61 loss: 1.1306432112056774e-05
BFGS Iter: 62 loss: 1.1288200587281669e-05
BFGS Iter: 63 loss: 1.1272524142312414e-05
BFGS Iter: 64 loss: 1.1266858116681203e-05
BFGS Iter: 65 loss: 1.1253927459287215e-05
BFGS Iter: 66 loss: 1.1236607367987663e-05
BFGS Iter: 67 loss: 1.121619986484418e-05
BFGS Iter: 68 loss: 1.120775718419495e-05
BFGS Iter: 69 loss: 1.1206452393275113e-05
BFGS Iter: 70 loss: 1.1206267834597727e-05
BFGS Iter: 71 loss: 1.1205816838928572e-05
BFGS Iter: 72 loss: 1.1202193385177711e-05
BFGS Iter: 73 loss: 1.1194368907026998e-05
BFGS Iter: 74 loss: 1.1183837415402236e-05
BFGS Iter: 75 loss: 1.1174997964410506e-05
BFGS Iter: 76 loss: 1.1171030563697652e-05
BFGS Iter: 77 loss: 1.1170242325112961e-05
BFGS Iter: 78 loss: 1.116710340229912e-05
BFGS Iter: 79 loss: 1.1142125068001499e-05
BFGS Iter: 80 loss: 1.1135492609919581e-05
BFGS Iter: 81 loss: 1.1133476119579804e-05
BFGS Iter: 82 loss: 1.1133258709515484e-05
BFGS Iter: 83 loss: 1.1133026775013508e-05
BFGS Iter: 84 loss: 1.1132451389931068e-05
BFGS Iter: 85 loss: 1.1130934728269286e-05
BFGS Iter: 86 loss: 1.112715593477359e-05
BFGS Iter: 87 loss: 1.1118315783131395e-05
BFGS Iter: 88 loss: 1.1101161602659784e-05
BFGS Iter: 89 loss: 1.107922939843552e-05
BFGS Iter: 90 loss: 1.1063589810676235e-05
BFGS Iter: 91 loss: 1.105754572859437e-05
BFGS Iter: 92 loss: 1.1056549014404436e-05
BFGS Iter: 93 loss: 1.1055826285149645e-05
BFGS Iter: 94 loss: 1.1053544796972902e-05
BFGS Iter: 95 loss: 1.1048119382793432e-05
BFGS Iter: 96 loss: 1.1036070754941427e-05
BFGS Iter: 97 loss: 1.1016533819418808e-05
BFGS Iter: 98 loss: 1.0985942212474907e-05
BFGS Iter: 99 loss: 1.0969796385295971e-05
BFGS Iter: 100 loss: 1.0964485214369811e-05
BFGS Iter: 101 loss: 1.0959386904055931e-05
Elapsed time 14.2118 sec
Tolerance reached. Current loss: 1.095938690405593e-05 Batches: 5
Elapsed time for training 94.0623 sec
</pre></div>
</div>
</div>
</details>
</div>
<p>Now that we have a solution, we can compute variables of interest, which can subsequently be used to compute shock elasticities. By default, <code class="docutils literal notranslate"><span class="pre">main_variable</span></code> computes the following variables. Unless specified otherwise, the variables are evaluated on an array with dimension [<code class="docutils literal notranslate"><span class="pre">nWealth</span></code>,<code class="docutils literal notranslate"><span class="pre">nZ</span></code>,<code class="docutils literal notranslate"><span class="pre">nV</span></code>].</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Input</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Parameter used in paper</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">W_NN</span></code>, <code class="docutils literal notranslate"><span class="pre">Z_NN</span></code>, <code class="docutils literal notranslate"><span class="pre">V_NN</span></code></p></td>
<td><p>The values of <span class="math notranslate nohighlight">\(W\)</span>, <span class="math notranslate nohighlight">\(Z_1\)</span> and <span class="math notranslate nohighlight">\(Z_2\)</span> on the state-space grid</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">XiE_NN</span></code>, <code class="docutils literal notranslate"><span class="pre">XiH_NN</span></code></p></td>
<td><p>Expert and household value functions</p></td>
<td><p><span class="math notranslate nohighlight">\(V_e\)</span>, <span class="math notranslate nohighlight">\(V_h\)</span></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">logXiE_NN</span></code>, <code class="docutils literal notranslate"><span class="pre">logXiH_NN</span></code></p></td>
<td><p>Log expert and household value functions</p></td>
<td><p><span class="math notranslate nohighlight">\(\hat{V}_e\)</span>, <span class="math notranslate nohighlight">\(\hat{V}_h\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">chi_NN</span></code></p></td>
<td><p>Expert equity retention</p></td>
<td><p><span class="math notranslate nohighlight">\(\chi\)</span></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kappa_NN</span></code></p></td>
<td><p>Expert capital share</p></td>
<td><p><span class="math notranslate nohighlight">\(\kappa\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">r_NN</span></code></p></td>
<td><p>Risk-free rate</p></td>
<td><p><span class="math notranslate nohighlight">\(r\)</span></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">q_NN</span></code></p></td>
<td><p>Price of capital</p></td>
<td><p><span class="math notranslate nohighlight">\(Q\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">sigmaW_NN</span></code>,<code class="docutils literal notranslate"><span class="pre">sigmaZ_NN</span></code>,<code class="docutils literal notranslate"><span class="pre">sigmaV_NN</span></code></p></td>
<td><p>State volatilities</p></td>
<td><p><span class="math notranslate nohighlight">\(Z^2 \sigma_w\)</span>,<span class="math notranslate nohighlight">\(Z^2 \sigma_1\)</span>, <span class="math notranslate nohighlight">\(Z^2 \sigma_2\)</span></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">muW_NN</span></code>,<code class="docutils literal notranslate"><span class="pre">muZ_NN</span></code>,<code class="docutils literal notranslate"><span class="pre">muV_NN</span></code></p></td>
<td><p>State drifts</p></td>
<td><p><span class="math notranslate nohighlight">\(\mu_w\)</span>,<span class="math notranslate nohighlight">\(\mu_1\)</span>,<span class="math notranslate nohighlight">\(\mu_2\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">muK_NN</span></code></p></td>
<td><p>Log capital drift</p></td>
<td><p><span class="math notranslate nohighlight">\(\mu_{k}\)</span></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">sigmaK_NN</span></code></p></td>
<td><p>Log capital diffusin</p></td>
<td><p><span class="math notranslate nohighlight">\(\sigma_{k}\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">muQ_NN</span></code></p></td>
<td><p>Capital price drift</p></td>
<td><p><span class="math notranslate nohighlight">\(\mu_q\)</span></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">sigmaQ_NN</span></code></p></td>
<td><p>Capital price diffusion</p></td>
<td><p><span class="math notranslate nohighlight">\(\sigma_q\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">sigmaR_NN</span></code></p></td>
<td><p>Capital return volatility</p></td>
<td><p><span class="math notranslate nohighlight">\(\sigma_r\)</span></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">deltaE_NN</span></code>, <code class="docutils literal notranslate"><span class="pre">deltaH_NN</span></code></p></td>
<td><p>Expert and household risk premium wedge</p></td>
<td><p><span class="math notranslate nohighlight">\(\Delta^e\)</span>,<span class="math notranslate nohighlight">\(\Delta^h\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">PiE_NN</span></code>, <code class="docutils literal notranslate"><span class="pre">PiH_NN</span></code></p></td>
<td><p>Expert and household equity risk price</p></td>
<td><p><span class="math notranslate nohighlight">\(\pi_e\)</span>,<span class="math notranslate nohighlight">\(\pi_h\)</span></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">betaE_NN</span></code>,<code class="docutils literal notranslate"><span class="pre">betaH_NN</span></code></p></td>
<td></td>
<td><p><span class="math notranslate nohighlight">\(\frac{\chi \kappa}{W}\)</span>, <span class="math notranslate nohighlight">\(\frac{1- \kappa}{W}\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">HJB_E_NN</span></code>, <code class="docutils literal notranslate"><span class="pre">HJB_H_NN</span></code>, <code class="docutils literal notranslate"><span class="pre">kappa_min_NN</span></code></p></td>
<td><p>RHS of HJB equations and <span class="math notranslate nohighlight">\(\kappa\)</span> constraint evaluated on the state space grid</p></td>
<td><p><span class="math notranslate nohighlight">\(L^e\)</span>, <span class="math notranslate nohighlight">\(L^h\)</span>, <span class="math notranslate nohighlight">\(L^{\kappa}\)</span></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">HJBE_validation_MSE</span></code>, <code class="docutils literal notranslate"><span class="pre">HJBH_validation_MSE</span></code>, <code class="docutils literal notranslate"><span class="pre">kappa_validation_MSE</span></code></p></td>
<td><p>Loss function (scalar)</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">dent_NN</span></code></p></td>
<td><p>Stationary density</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">dX_logXiE_NN</span></code>, <code class="docutils literal notranslate"><span class="pre">dX_logXiH_NN</span></code>, <code class="docutils literal notranslate"><span class="pre">dX2_logXiE_NN</span></code>, <code class="docutils literal notranslate"><span class="pre">dX2_logXiH_NN</span></code></p></td>
<td><p>First and second derivatives of expert and household value function with respect to each of the states; separate objects for each state are also included</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mulogSe_NN</span></code>, <code class="docutils literal notranslate"><span class="pre">mulogSh_NN</span></code></p></td>
<td><p>Log SDF drifts for expert and household</p></td>
<td><p><span class="math notranslate nohighlight">\(-r_t S_t^e\)</span>, <span class="math notranslate nohighlight">\(-r_t S_t^h\)</span></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">sigmalogSe_NN</span></code>, <code class="docutils literal notranslate"><span class="pre">sigmalogSh_NN</span></code></p></td>
<td><p>Log SDF diffusions for expert and household</p></td>
<td><p><span class="math notranslate nohighlight">\(-S_t^e \pi_t^e\)</span>, <span class="math notranslate nohighlight">\(-S_t^h \pi_t^h\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mulogCe_NN</span></code>, <code class="docutils literal notranslate"><span class="pre">mulogCh_NN</span></code></p></td>
<td><p>Log consumption drifts for expert and household</p></td>
<td><p><span class="math notranslate nohighlight">\(\hat{\mu}_c^e\)</span>, <span class="math notranslate nohighlight">\(\hat{\mu}_c^h\)</span></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">sigmalogCe_NN</span></code>, <code class="docutils literal notranslate"><span class="pre">sigmalogCh_NN</span></code></p></td>
<td><p>Log consumption diffusions for expert and household</p></td>
<td><p><span class="math notranslate nohighlight">\(\sigma_c^e\)</span>, <span class="math notranslate nohighlight">\(\sigma_c^h\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">mulogC_NN</span></code></p></td>
<td><p>Log aggregate consumption drift</p></td>
<td><p><span class="math notranslate nohighlight">\(\hat{\mu}_c\)</span></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">sigmalogC_NN</span></code></p></td>
<td><p>Log aggregate consumption diffusion</p></td>
<td><p><span class="math notranslate nohighlight">\(\sigma_c\)</span></p></td>
</tr>
</tbody>
</table>
<p>Given that a solution has been saved under the same parameters, the following code outputs the variables listed above. In addition, the <code class="docutils literal notranslate"><span class="pre">marginal_quantile_func_factory</span></code> function is called to save the above outputs evaluated at desired quantiles (e.g. <span class="math notranslate nohighlight">\(Z^2\)</span> at median) for ease of plotting.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s1">&#39;src/4&#39;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">main_variable</span> <span class="kn">import</span> <span class="n">main_var</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s1">&#39;../..&#39;</span><span class="p">)</span>

<span class="n">main_var</span><span class="p">(</span><span class="n">action_name</span><span class="p">,</span> <span class="n">nWealth</span><span class="p">,</span> <span class="n">nZ</span><span class="p">,</span> <span class="n">nV</span><span class="p">,</span> <span class="n">V_bar</span><span class="p">,</span> <span class="n">sigma_K_norm</span><span class="p">,</span> <span class="n">sigma_Z_norm</span><span class="p">,</span> <span class="n">sigma_V_norm</span><span class="p">,</span> <span class="n">wMin</span><span class="p">,</span> <span class="n">wMax</span><span class="p">,</span> <span class="n">chiUnderline</span><span class="p">,</span> <span class="n">a_e</span><span class="p">,</span> <span class="n">a_h</span><span class="p">,</span> <span class="n">gamma_e</span><span class="p">,</span> <span class="n">gamma_h</span><span class="p">,</span> <span class="n">rho_e</span><span class="p">,</span> <span class="n">rho_h</span><span class="p">,</span> <span class="n">delta_e</span><span class="p">,</span> <span class="n">delta_h</span><span class="p">,</span> <span class="n">lambda_d</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">shock_expo</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">units</span><span class="p">,</span> <span class="n">points_size</span><span class="p">,</span> <span class="n">iter_num</span><span class="p">,</span> <span class="n">seed</span><span class="p">,</span> <span class="n">penalization</span><span class="p">,</span> <span class="n">BFGS_maxiter</span><span class="p">,</span> <span class="n">BFGS_maxfun</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024-08-28 15:49:17.685366: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
</pre></div>
</div>
</div>
</div>
<p>We can now plot the results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s1">&#39;src/4&#39;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">plot</span> <span class="kn">import</span> <span class="n">return_NN_solution</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s1">&#39;../..&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s2">&quot;whitegrid&quot;</span><span class="p">,</span> <span class="n">font_scale</span><span class="o">=</span><span class="mf">1.13</span><span class="p">,</span> <span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;lines.linewidth&quot;</span><span class="p">:</span> <span class="mf">3.5</span><span class="p">})</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;axes.formatter.useoffset&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>
</div>
</div>
</div>
<p>First we load in the results using the same parameters as before.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="n">return_NN_solution</span><span class="p">(</span><span class="n">shock_expo</span><span class="o">=</span><span class="n">shock_expo</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span> <span class="n">chiUnderline</span><span class="o">=</span><span class="n">chiUnderline</span><span class="p">,</span> <span class="n">a_e</span><span class="o">=</span><span class="n">a_e</span><span class="p">,</span> <span class="n">a_h</span><span class="o">=</span><span class="n">a_h</span><span class="p">,</span> <span class="n">gamma_e</span><span class="o">=</span><span class="n">gamma_e</span><span class="p">,</span> <span class="n">gamma_h</span><span class="o">=</span><span class="n">gamma_h</span><span class="p">,</span> <span class="n">psi_e</span><span class="o">=</span><span class="n">rho_e</span><span class="p">,</span> <span class="n">psi_h</span><span class="o">=</span><span class="n">rho_h</span><span class="p">,</span> <span class="n">delta_e</span><span class="o">=</span><span class="n">delta_e</span><span class="p">,</span> <span class="n">delta_h</span><span class="o">=</span><span class="n">delta_h</span><span class="p">,</span> <span class="n">lambda_d</span><span class="o">=</span><span class="n">lambda_d</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="n">nu</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="n">units</span><span class="p">,</span> <span class="n">iter_num</span><span class="o">=</span><span class="n">iter_num</span><span class="p">,</span> <span class="n">points_size</span><span class="o">=</span><span class="n">points_size</span><span class="p">,</span> <span class="n">penalization</span><span class="o">=</span><span class="n">penalization</span><span class="p">,</span> <span class="n">action_name</span><span class="o">=</span><span class="n">action_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We provide an example plot below. Notice that we use <code class="docutils literal notranslate"><span class="pre">results['eva_V_10']</span></code> and <code class="docutils literal notranslate"><span class="pre">results['eva_V_90']</span></code> to extract the variables of interest evaluated at <span class="math notranslate nohighlight">\(Z^1=0\)</span> and <span class="math notranslate nohighlight">\(Z^2\)</span> at its 10th and 90th percentiles, respectively.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">W_dense</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;eva_V_50&#39;</span><span class="p">][</span><span class="s1">&#39;W&#39;</span><span class="p">])</span>
<span class="n">W_sparse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;W&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">W_dense</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;eva_V_10&#39;</span><span class="p">][</span><span class="s1">&#39;PiE_NN&#39;</span><span class="p">][:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">W_dense</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;eva_V_90&#39;</span><span class="p">][</span><span class="s1">&#39;PiE_NN&#39;</span><span class="p">][:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">)</span>
<span class="n">ax2</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">twinx</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">W_sparse</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;dentW&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax2</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.03</span><span class="p">])</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;W&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/9897f50d4fc918af41a081f94fe662240899bf69494f7b016d1a6f8710a1d588.png" src="_images/9897f50d4fc918af41a081f94fe662240899bf69494f7b016d1a6f8710a1d588.png" />
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="finite-difference-method">
<h1>Finite Difference Method<a class="headerlink" href="#finite-difference-method" title="Permalink to this heading">#</a></h1>
<p>We employ finite differences to solve Model IP from Section 5.</p>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "envname"
        },
        kernelOptions: {
            name: "envname",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'envname'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="twocapital.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">3 Two Capital Model</p>
      </div>
    </a>
    <a class="right-next"
       href="elasticities.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">4 Elasticities</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">4 Heterogeneous Agents</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#solution-overview">Solution Overview</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-architecture">Model Architecture</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training">Training</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-parameters">Model Parameters</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#finite-difference-method">Finite Difference Method</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Lars Peter Hansen, Paymon Khorrami and Fabrice Tourre
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>